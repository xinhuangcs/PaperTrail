{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro_md",
   "metadata": {},
   "source": [
    "# 3.1 Similarity Search\n",
    "\n",
    "This notebook implements similarity search for the PaperTrail, aiming to find the top 100 most relevant papers from our database of 700,000 papers.  \n",
    "This will be used for subsequent recommendation systems.\n",
    "\n",
    "It supports three methods:\n",
    "1. **TF-IDF**: Traditional sparse vector search.\n",
    "2. **LSA + LSH**: LSA combined with Locally Sensitive Hashing for approximate nearest neighbour search.\n",
    "3. **SBERT Encoding**: Search based on HDBscan results.\n",
    "\n",
    "As **LSA + LSH** uses the LSH algorithm, which significantly accelerates search execution, this notebook mainly introduces this method.\n",
    "\n",
    "The code is adapted from `src/search/similarity_search_v4.py`."
   ]
  },
  {
   "cell_type": "code",
   "id": "imports_code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T19:55:01.801763Z",
     "start_time": "2025-12-04T19:55:01.163482Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "import re, time, json\n",
    "import numpy as np\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from collections import defaultdict\n",
    "from scipy import sparse\n",
    "from importlib import import_module\n",
    "import argparse\n",
    "\n",
    "try:\n",
    "    PorterStemmer = import_module(\"nltk.stem\").PorterStemmer\n",
    "    STEMMER = PorterStemmer()\n",
    "except Exception:\n",
    "    STEMMER = None\n",
    "    print(\"[warn] NLTK PorterStemmer unavailable; queries won't be stemmed.\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "config_md",
   "metadata": {},
   "source": [
    "## Configuration and Paths\n",
    "\n",
    "Here we define the file paths and constants used throughout the notebook.\n",
    "Note that `ROOT_DIR` is set relative to the notebook location."
   ]
  },
  {
   "cell_type": "code",
   "id": "config_code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T19:56:14.850613Z",
     "start_time": "2025-12-04T19:56:14.846367Z"
    }
   },
   "source": [
    "# 1) paths\n",
    "# Assuming notebook is in /src/jupyter_notebook/ folder, so root is one level up\n",
    "ROOT_DIR = Path(\"..\").resolve()\n",
    "DATA_DIR = ROOT_DIR / \"data\"\n",
    "TFIDF_DIR = DATA_DIR / \"tf_idf\"\n",
    "LSA_DIR = DATA_DIR / \"lsa\"\n",
    "OUT_DIR = DATA_DIR / \"similarity_results\" / \"similarity_results_v2\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "LSH_PARAMS = {\n",
    "    \"n_planes\": 48,\n",
    "    \"band_size\": 4,\n",
    "    \"seed\": 13,\n",
    "    \"max_candidates\": 800,\n",
    "}\n",
    "\n",
    "_LSH_CACHE: Optional[Dict[str, object]] = None\n",
    "\n",
    "# 2) inputs (big matrices)\n",
    "DOC_IDS_PATH = TFIDF_DIR / \"doc_ids.npy\"\n",
    "DOC_TITLES_PATH = TFIDF_DIR / \"doc_titles.npy\"\n",
    "TFIDF_MATRIX_PATH = TFIDF_DIR / \"tfidf_matrix.npz\"\n",
    "LSA_MATRIX_PATH = LSA_DIR / \"lsa_reduced.npz\" \n",
    "LSA_CLUSTER_LABELS_PATH = LSA_DIR / \"cluster_labels.npy\"\n",
    "LSA_CLUSTER_TOPICS_JSON = ROOT_DIR /\"src\"/\"cluster_topics.json\"\n",
    "\n",
    "# 3) artifacts (read them from similarity_results_v2)\n",
    "VOCAB_JSON = OUT_DIR / \"vocab.json\"\n",
    "IDF_NPY = OUT_DIR / \"idf.npy\"\n",
    "USE_L2_TXT = OUT_DIR / \"use_l2_norm.txt\"\n",
    "SVD_COMPONENTS_NPY = OUT_DIR / \"svd_components.npy\"\n",
    "NCOMP_TXT = OUT_DIR / \"n_components.txt\"\n",
    "TFIDF_ROW_NORMS_NPY = OUT_DIR / \"row_l2_norms.npy\"\n",
    "LSA_PRENORM_NPZ = OUT_DIR / \"lsa_reduced_l2norm.npz\"\n",
    "\n",
    "RAW_JSONL_PATH = DATA_DIR / \"preprocess\" / \"arxiv-cs-data-with-citations-final-dataset_preprocessed.json\"\n",
    "CUSTOM_STOPWORDS_PATH = ROOT_DIR / \"src\" / \"custom_stopwords.txt\""
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "text_proc_md",
   "metadata": {},
   "source": [
    "## Text Processing\n",
    "\n",
    "Functions to load custom stopwords and preprocess search queries.\n",
    "Preprocessing includes lowercasing, removing special characters, filtering stopwords, and stemming."
   ]
  },
  {
   "cell_type": "code",
   "id": "text_proc_code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T19:56:59.365925Z",
     "start_time": "2025-12-04T19:56:59.360379Z"
    }
   },
   "source": [
    "def load_custom_stopwords() -> set:\n",
    "#Load custom stopwords from file\n",
    "    if not CUSTOM_STOPWORDS_PATH.exists():\n",
    "        print(f\"[warn] Custom stopwords file not found: {CUSTOM_STOPWORDS_PATH}\")\n",
    "        return set()\n",
    "    \n",
    "    try:\n",
    "        stopwords_set = {\n",
    "            line.strip().lower()\n",
    "            for line in CUSTOM_STOPWORDS_PATH.read_text(encoding=\"utf-8\").splitlines()\n",
    "            if line.strip()\n",
    "        }\n",
    "        print(f\"[i] Loaded {len(stopwords_set)} custom stopwords.\")\n",
    "        return stopwords_set\n",
    "    except Exception as exc:\n",
    "        print(f\"[warn] Failed to load custom stopwords: {exc}\")\n",
    "        return set()\n",
    "\n",
    "\n",
    "_CUSTOM_STOPWORDS: Optional[set] = None\n",
    "\n",
    "def get_custom_stopwords() -> set:\n",
    "#Get custom stopwords\n",
    "    global _CUSTOM_STOPWORDS\n",
    "    if _CUSTOM_STOPWORDS is None:\n",
    "        _CUSTOM_STOPWORDS = load_custom_stopwords()\n",
    "    return _CUSTOM_STOPWORDS\n",
    "\n",
    "\n",
    "def preprocess_query(q: str) -> str:\n",
    "    # lowercase + keep [a-z0-9] + collapse spaces\n",
    "    q = q.lower()\n",
    "    q = re.sub(r\"[^a-z0-9\\s]+\", \" \", q)\n",
    "    q = re.sub(r\"\\s+\", \" \", q).strip()\n",
    "\n",
    "    tokens = q.split()\n",
    "\n",
    "    # Filter custom stopwords\n",
    "    custom_stopwords = get_custom_stopwords()\n",
    "    if custom_stopwords:\n",
    "        tokens = [token for token in tokens if token not in custom_stopwords]\n",
    "\n",
    "    # Apply stemming to match training-time preprocessing\n",
    "    if STEMMER is not None:\n",
    "        tokens = [STEMMER.stem(token) for token in tokens]\n",
    "\n",
    "    return \" \".join(tokens)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "artifacts_md",
   "metadata": {},
   "source": [
    "## Artifact Loading\n",
    "\n",
    "Load the necessary data files (vocabulary, IDF, SVD components, document IDs, etc.) required for search."
   ]
  },
  {
   "cell_type": "code",
   "id": "artifacts_code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T19:57:14.579645Z",
     "start_time": "2025-12-04T19:57:14.574587Z"
    }
   },
   "source": [
    "def load_minimal_artifacts():\n",
    "    # load small pieces\n",
    "    vocab = json.loads(VOCAB_JSON.read_text(encoding=\"utf-8\"))\n",
    "    idf = np.load(IDF_NPY)\n",
    "    use_l2 = USE_L2_TXT.read_text().strip() == \"1\"\n",
    "    comps = np.load(SVD_COMPONENTS_NPY)   # (k, V)\n",
    "    ncomp = int(NCOMP_TXT.read_text().strip() or comps.shape[0])\n",
    "    doc_ids = np.load(DOC_IDS_PATH, allow_pickle=True)\n",
    "    doc_titles = np.load(DOC_TITLES_PATH, allow_pickle=True)\n",
    "\n",
    "    cluster_labels: Optional[np.ndarray] = None\n",
    "    if LSA_CLUSTER_LABELS_PATH.exists():\n",
    "        cluster_labels = np.load(LSA_CLUSTER_LABELS_PATH)\n",
    "        if cluster_labels.shape[0] != doc_ids.shape[0]:\n",
    "            print(\n",
    "                \"[warn] LSA cluster labels length mismatch; ignoring cluster mapping \"\n",
    "                f\"({cluster_labels.shape[0]} vs {doc_ids.shape[0]})\"\n",
    "            )\n",
    "            cluster_labels = None\n",
    "    else:\n",
    "        print(\"[info] LSA cluster labels not found; cluster ids will be omitted.\")\n",
    "\n",
    "    cluster_topics: Optional[Dict[int, List[str]]] = None\n",
    "    if LSA_CLUSTER_TOPICS_JSON.exists():\n",
    "        try:\n",
    "            raw_topics = json.loads(LSA_CLUSTER_TOPICS_JSON.read_text(encoding=\"utf-8\"))\n",
    "            if isinstance(raw_topics, dict):\n",
    "                cluster_topics = {}\n",
    "                for key, value in raw_topics.items():\n",
    "                    try:\n",
    "                        cid = int(key)\n",
    "                    except (TypeError, ValueError):\n",
    "                        continue\n",
    "                    if isinstance(value, (list, tuple)):\n",
    "                        cluster_topics[cid] = [str(t) for t in value]\n",
    "                    else:\n",
    "                        cluster_topics[cid] = [str(value)]\n",
    "        except Exception as exc:\n",
    "            print(f\"[warn] failed to load cluster topics: {exc}\")\n",
    "\n",
    "    return (\n",
    "        vocab,\n",
    "        idf,\n",
    "        use_l2,\n",
    "        comps,\n",
    "        ncomp,\n",
    "        doc_ids,\n",
    "        doc_titles,\n",
    "        cluster_labels,\n",
    "        cluster_topics,\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "vector_ops_md",
   "metadata": {},
   "source": [
    "## Vector Operations\n",
    "\n",
    "Helper functions to convert queries to TF-IDF vectors and perform L2 normalization."
   ]
  },
  {
   "cell_type": "code",
   "id": "vector_ops_code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T19:57:26.761831Z",
     "start_time": "2025-12-04T19:57:26.756948Z"
    }
   },
   "source": [
    "def query_to_tfidf_vec(query: str, vocab: dict, idf: np.ndarray, verbose: bool = False) -> sparse.csr_matrix:\n",
    "    # tf (relative) * idf, then l2 norm\n",
    "    tokens = query.split()\n",
    "    counts = {}\n",
    "    missing_tokens = []\n",
    "    for t in tokens:\n",
    "        j = vocab.get(t)\n",
    "        if j is not None:\n",
    "            counts[j] = counts.get(j, 0) + 1\n",
    "        else:\n",
    "            missing_tokens.append(t)\n",
    "    if verbose and missing_tokens:\n",
    "        print(f\"[info] Query tokens not in vocabulary: {missing_tokens}\")\n",
    "    if not counts:\n",
    "        return sparse.csr_matrix((1, idf.shape[0]))\n",
    "    cols = np.fromiter(counts.keys(), dtype=np.int32)\n",
    "    tf = np.fromiter(counts.values(), dtype=np.float64)\n",
    "    tf = tf / tf.sum()\n",
    "    data = tf * idf[cols]\n",
    "    vec = sparse.csr_matrix((data, (np.zeros_like(cols), cols)), shape=(1, idf.shape[0]))\n",
    "    norm = np.sqrt((vec.multiply(vec)).sum())\n",
    "    if norm > 0:\n",
    "        vec /= norm\n",
    "    return vec\n",
    "\n",
    "def l2_normalize_dense(A: np.ndarray) -> np.ndarray:\n",
    "    # row-wise l2 norm\n",
    "    n = np.linalg.norm(A, axis=1, keepdims=True)\n",
    "    n[n == 0] = 1.0\n",
    "    return A / n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "search_methods_md",
   "metadata": {},
   "source": [
    "## Search Methods\n",
    "\n",
    "Implementation of the three search strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tfidf_md",
   "metadata": {},
   "source": [
    "### 1. TF-IDF Search\n",
    "Uses cosine similarity on sparse TF-IDF vectors."
   ]
  },
  {
   "cell_type": "code",
   "id": "tfidf_code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T19:57:53.555039Z",
     "start_time": "2025-12-04T19:57:53.551243Z"
    }
   },
   "source": [
    "def cosine_topk_sparse(q: sparse.csr_matrix, D: sparse.csr_matrix, k: int, D_row_norms=None):\n",
    "    # cosine for sparse\n",
    "    sims = (q @ D.T).toarray().ravel()\n",
    "    if D_row_norms is not None:\n",
    "        safe = D_row_norms.copy()\n",
    "        safe[safe == 0] = 1.0\n",
    "        sims = sims / safe\n",
    "    if k >= len(sims):\n",
    "        top = np.argsort(-sims)\n",
    "    else:\n",
    "        top = np.argpartition(-sims, k)[:k]\n",
    "        top = top[np.argsort(-sims[top])]\n",
    "    return top, sims\n",
    "\n",
    "def search_tfidf(query: str, top_k: int) -> List[Tuple[str, str, float, Optional[int], Optional[List[str]]]]:\n",
    "    # tfidf retrieval\n",
    "    (\n",
    "        vocab,\n",
    "        idf,\n",
    "        use_l2,\n",
    "        comps,\n",
    "        ncomp,\n",
    "        doc_ids,\n",
    "        doc_titles,\n",
    "        cluster_labels,\n",
    "        cluster_topics,\n",
    "    ) = load_minimal_artifacts()\n",
    "    X = sparse.load_npz(TFIDF_MATRIX_PATH)\n",
    "    q = query_to_tfidf_vec(preprocess_query(query), vocab, idf, verbose=False)\n",
    "    D_norms = np.load(TFIDF_ROW_NORMS_NPY) if TFIDF_ROW_NORMS_NPY.exists() else None\n",
    "    top_idx, sims = cosine_topk_sparse(q, X, top_k, D_norms)\n",
    "    results: List[Tuple[str, str, float, Optional[int], Optional[List[str]]]] = []\n",
    "    for i in top_idx:\n",
    "        if sims[i] > 0:\n",
    "            cluster_id: Optional[int] = None\n",
    "            cluster_topics_list: Optional[List[str]] = None\n",
    "            if cluster_labels is not None and i < cluster_labels.shape[0]:\n",
    "                cluster_id = int(cluster_labels[i])\n",
    "                if cluster_topics is not None:\n",
    "                    topics = cluster_topics.get(cluster_id)\n",
    "                    if topics is not None:\n",
    "                        cluster_topics_list = list(topics)\n",
    "            results.append(\n",
    "                (\n",
    "                    str(doc_ids[i]),\n",
    "                    str(doc_titles[i]),\n",
    "                    float(sims[i]),\n",
    "                    cluster_id,\n",
    "                    cluster_topics_list,\n",
    "                )\n",
    "            )\n",
    "    return results"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "lsa_md",
   "metadata": {},
   "source": [
    "### 2. LSA Search\n",
    "Projects the query into the reduced LSA space and computes cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "id": "lsa_code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T19:58:00.529589Z",
     "start_time": "2025-12-04T19:58:00.523644Z"
    }
   },
   "source": [
    "def _load_lsa_matrix() -> np.ndarray:\n",
    "    if LSA_PRENORM_NPZ.exists():\n",
    "        d = np.load(LSA_PRENORM_NPZ, allow_pickle=False)\n",
    "        try:\n",
    "            return d[\"Xr_norm\"]\n",
    "        finally:\n",
    "            if hasattr(d, \"close\"):\n",
    "                d.close()\n",
    "    d = np.load(LSA_MATRIX_PATH, allow_pickle=False)\n",
    "    try:\n",
    "        Xr = d[\"X_reduced\"]\n",
    "    finally:\n",
    "        if hasattr(d, \"close\"):\n",
    "            d.close()\n",
    "    return l2_normalize_dense(Xr)\n",
    "\n",
    "def search_lsa(query: str, top_k: int) -> List[Tuple[str, str, float, Optional[int], Optional[List[str]]]]:\n",
    "    # lsa retrieval\n",
    "    (\n",
    "        vocab,\n",
    "        idf,\n",
    "        use_l2,\n",
    "        comps,\n",
    "        ncomp,\n",
    "        doc_ids,\n",
    "        doc_titles,\n",
    "        cluster_labels,\n",
    "        cluster_topics,\n",
    "    ) = load_minimal_artifacts()\n",
    "    d = np.load(LSA_MATRIX_PATH)\n",
    "    Xr = d[\"X_reduced\"]\n",
    "    if LSA_PRENORM_NPZ.exists():\n",
    "        Xr = np.load(LSA_PRENORM_NPZ)[\"Xr_norm\"]\n",
    "    else:\n",
    "        Xr = l2_normalize_dense(Xr)\n",
    "    q_tfidf = query_to_tfidf_vec(preprocess_query(query), vocab, idf, verbose=False).toarray()\n",
    "    \n",
    "    # Check and adjust dimensions to match comps\n",
    "    vocab_size = q_tfidf.shape[1]\n",
    "    comps_vocab_size = comps.shape[1]\n",
    "    \n",
    "    if vocab_size != comps_vocab_size:\n",
    "        # Pad or truncate q_tfidf to match comps dimensions\n",
    "        if vocab_size < comps_vocab_size:\n",
    "            # Pad with zeros if vocab is smaller\n",
    "            padding = np.zeros((1, comps_vocab_size - vocab_size))\n",
    "            q_tfidf = np.hstack([q_tfidf, padding])\n",
    "        else:\n",
    "            # Truncate if vocab is larger\n",
    "            q_tfidf = q_tfidf[:, :comps_vocab_size]\n",
    "        print(f\"[warn] vocab size mismatch: {vocab_size} vs {comps_vocab_size}, adjusted\")\n",
    "    \n",
    "    q_lsa = q_tfidf @ comps.T\n",
    "    q_lsa = l2_normalize_dense(q_lsa)\n",
    "    sims = (q_lsa @ Xr.T).ravel()\n",
    "    if top_k >= len(sims):\n",
    "        top = np.argsort(-sims)\n",
    "    else:\n",
    "        top = np.argpartition(-sims, top_k)[:top_k]\n",
    "        top = top[np.argsort(-sims[top])]\n",
    "    results: List[Tuple[str, str, float, Optional[int], Optional[List[str]]]] = []\n",
    "    for i in top:\n",
    "        if sims[i] > 0:\n",
    "            cluster_id: Optional[int] = None\n",
    "            cluster_topics_list: Optional[List[str]] = None\n",
    "            if cluster_labels is not None and i < cluster_labels.shape[0]:\n",
    "                cluster_id = int(cluster_labels[i])\n",
    "                if cluster_topics is not None:\n",
    "                    topics = cluster_topics.get(cluster_id)\n",
    "                    if topics is not None:\n",
    "                        cluster_topics_list = list(topics)\n",
    "            results.append(\n",
    "                (\n",
    "                    str(doc_ids[i]),\n",
    "                    str(doc_titles[i]),\n",
    "                    float(sims[i]),\n",
    "                    cluster_id,\n",
    "                    cluster_topics_list,\n",
    "                )\n",
    "            )\n",
    "    return results"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "lsh_md",
   "metadata": {},
   "source": [
    "### 3. LSA + LSH Search\n",
    "Uses Locality Sensitive Hashing to quickly find candidate documents in the LSA space, then refines with exact cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "id": "lsh_code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T19:58:05.635992Z",
     "start_time": "2025-12-04T19:58:05.625767Z"
    }
   },
   "source": [
    "def _build_lsh_cache() -> Dict[str, object]:\n",
    "    Xr = _load_lsa_matrix()\n",
    "    params = dict(LSH_PARAMS)\n",
    "    n_planes = params[\"n_planes\"]\n",
    "    band_size = max(1, min(params[\"band_size\"], n_planes))\n",
    "    seed = params[\"seed\"]\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    hyperplanes = rng.standard_normal((n_planes, Xr.shape[1]))\n",
    "    hyperplanes = l2_normalize_dense(hyperplanes)\n",
    "\n",
    "    projections = Xr @ hyperplanes.T\n",
    "    signatures = (projections >= 0).astype(np.uint8)\n",
    "\n",
    "    buckets: Dict[Tuple[int, int, int], Tuple[int, ...]] = {}\n",
    "    tmp = defaultdict(list)\n",
    "    for idx in range(signatures.shape[0]):\n",
    "        sig = signatures[idx]\n",
    "        for start in range(0, n_planes, band_size):\n",
    "            end = min(start + band_size, n_planes)\n",
    "            code = 0\n",
    "            for bit in sig[start:end]:\n",
    "                code = (code << 1) | int(bit)\n",
    "            key = (start // band_size, end - start, code)\n",
    "            tmp[key].append(idx)\n",
    "    for key, vals in tmp.items():\n",
    "        buckets[key] = tuple(vals)\n",
    "\n",
    "    return {\n",
    "        \"Xr\": Xr,\n",
    "        \"hyperplanes\": hyperplanes,\n",
    "        \"band_size\": band_size,\n",
    "        \"n_planes\": n_planes,\n",
    "        \"buckets\": buckets,\n",
    "    }\n",
    "\n",
    "\n",
    "def _get_lsh_cache() -> Dict[str, object]:\n",
    "    global _LSH_CACHE\n",
    "    if _LSH_CACHE is None:\n",
    "        _LSH_CACHE = _build_lsh_cache()\n",
    "    return _LSH_CACHE\n",
    "\n",
    "\n",
    "def _lsh_candidates(q_lsa: np.ndarray, cache: Dict[str, object]) -> List[int]:\n",
    "    hyperplanes = cache[\"hyperplanes\"]\n",
    "    band_size = cache[\"band_size\"]\n",
    "    n_planes = cache[\"n_planes\"]\n",
    "    buckets = cache[\"buckets\"]\n",
    "\n",
    "    projections = q_lsa @ hyperplanes.T\n",
    "    signature = (projections >= 0).astype(np.uint8).ravel()\n",
    "\n",
    "    cand = set()\n",
    "    for start in range(0, n_planes, band_size):\n",
    "        end = min(start + band_size, n_planes)\n",
    "        code = 0\n",
    "        for bit in signature[start:end]:\n",
    "            code = (code << 1) | int(bit)\n",
    "        key = (start // band_size, end - start, code)\n",
    "        bucket = buckets.get(key)\n",
    "        if bucket:\n",
    "            cand.update(bucket)\n",
    "    return list(cand)\n",
    "\n",
    "def search_lsa_lsh(\n",
    "    query: str,\n",
    "    top_k: int,\n",
    "    max_candidates: Optional[int] = None,\n",
    ") -> List[Tuple[str, str, float, Optional[int], Optional[List[str]]]]:\n",
    "    (\n",
    "        vocab,\n",
    "        idf,\n",
    "        _use_l2,\n",
    "        comps,\n",
    "        _ncomp,\n",
    "        doc_ids,\n",
    "        doc_titles,\n",
    "        cluster_labels,\n",
    "        cluster_topics,\n",
    "    ) = load_minimal_artifacts()\n",
    "\n",
    "    cache = _get_lsh_cache()\n",
    "    Xr = cache[\"Xr\"]\n",
    "    if max_candidates is None:\n",
    "        max_candidates = LSH_PARAMS.get(\"max_candidates\", 800)\n",
    "\n",
    "    preprocessed = preprocess_query(query)\n",
    "    if not preprocessed.strip():\n",
    "        print(f\"[warn] Query '{query}' became empty after preprocessing\")\n",
    "        print(f\"[info] All query terms were filtered out (likely stopwords)\")\n",
    "        print(f\"[info] Try using more specific technical terms\")\n",
    "        return []\n",
    "    \n",
    "    # Show preprocessing result and check vocabulary match\n",
    "    preprocessed_tokens = preprocessed.split()\n",
    "    missing_tokens = [t for t in preprocessed_tokens if t not in vocab]\n",
    "    found_tokens = [t for t in preprocessed_tokens if t in vocab]\n",
    "    \n",
    "    if found_tokens:\n",
    "        print(f\"[info] Query tokens found in vocabulary: {found_tokens}\")\n",
    "    if missing_tokens:\n",
    "        print(f\"[info] Query tokens not in vocabulary: {missing_tokens}\")\n",
    "    \n",
    "    q_tfidf = query_to_tfidf_vec(preprocessed, vocab, idf, verbose=False).toarray()\n",
    "    # Check if vector has any meaningful non-zero elements (using L2 norm check instead of sum)\n",
    "    q_tfidf_norm = np.linalg.norm(q_tfidf)\n",
    "    if q_tfidf_norm < 1e-10:\n",
    "        print(f\"[error] Query '{query}' (preprocessed: '{preprocessed}') produced zero TF-IDF vector\")\n",
    "        print(f\"[error] This means ALL query terms are not in the vocabulary\")\n",
    "        print(f\"[info] Preprocessed query tokens: {preprocessed_tokens}\")\n",
    "        print(f\"[info] Missing tokens: {missing_tokens}\")\n",
    "        print(f\"[info] Possible reasons:\")\n",
    "        print(f\"       1. Query terms don't exist in the training corpus\")\n",
    "        print(f\"       2. Spelling errors (e.g., 'quantumn' should be 'quantum')\")\n",
    "        print(f\"       3. Terms were filtered by stopwords or preprocessing\")\n",
    "        print(f\"[info] Suggestions:\")\n",
    "        print(f\"       - Check spelling (e.g., 'quantum' not 'quantumn')\")\n",
    "        print(f\"       - Use technical terms that appear in academic papers\")\n",
    "        print(f\"       - Try synonyms or related terms\")\n",
    "        return []\n",
    "    \n",
    "    # Check and adjust dimensions to match comps\n",
    "    vocab_size = q_tfidf.shape[1]\n",
    "    comps_vocab_size = comps.shape[1]\n",
    "    \n",
    "    if vocab_size != comps_vocab_size:\n",
    "        # Pad or truncate q_tfidf to match comps dimensions\n",
    "        if vocab_size < comps_vocab_size:\n",
    "            # Pad with zeros if vocab is smaller\n",
    "            padding = np.zeros((1, comps_vocab_size - vocab_size))\n",
    "            q_tfidf = np.hstack([q_tfidf, padding])\n",
    "        else:\n",
    "            # Truncate if vocab is larger\n",
    "            q_tfidf = q_tfidf[:, :comps_vocab_size]\n",
    "        print(f\"[warn] vocab size mismatch: {vocab_size} vs {comps_vocab_size}, adjusted\")\n",
    "    \n",
    "    q_lsa = q_tfidf @ comps.T\n",
    "    q_lsa_norm_before = np.linalg.norm(q_lsa)\n",
    "    q_lsa = l2_normalize_dense(q_lsa)\n",
    "    q_lsa_norm_after = np.linalg.norm(q_lsa)\n",
    "    \n",
    "    # Check if LSA transformation resulted in zero vector\n",
    "    if q_lsa_norm_before < 1e-10:\n",
    "        print(f\"[warn] Query LSA vector is near zero (norm={q_lsa_norm_before:.2e})\")\n",
    "        print(f\"[info] This may happen if query tokens map to zero or near-zero components in SVD space\")\n",
    "        # Still try to search, but with fallback to all documents\n",
    "\n",
    "    cand_idx = _lsh_candidates(q_lsa, cache)\n",
    "    if not cand_idx:\n",
    "        print(f\"[info] LSH found no candidates, falling back to full search\")\n",
    "        cand_idx = np.arange(Xr.shape[0], dtype=np.int32)\n",
    "    else:\n",
    "        cand_idx = np.array(cand_idx, dtype=np.int32)\n",
    "        if max_candidates and len(cand_idx) > max_candidates:\n",
    "            preview = (q_lsa @ Xr[cand_idx].T).ravel()\n",
    "            order = np.argsort(-preview)\n",
    "            cand_idx = cand_idx[order[:max_candidates]]\n",
    "\n",
    "    sims = (q_lsa @ Xr[cand_idx].T).ravel()\n",
    "    if sims.size == 0:\n",
    "        print(f\"[error] No candidates to compute similarity with\")\n",
    "        return []\n",
    "    \n",
    "    # Find the maximum similarity to check if we have meaningful matches\n",
    "    max_sim = np.max(sims) if sims.size > 0 else 0.0\n",
    "    if max_sim <= 0:\n",
    "        print(f\"[warn] All similarities are non-positive (max={max_sim:.2e})\")\n",
    "        print(f\"[info] This may indicate the query vector doesn't match well with any documents\")\n",
    "        # Still return top-k, even if similarities are low/negative\n",
    "\n",
    "    if top_k >= sims.size:\n",
    "        order = np.argsort(-sims)\n",
    "    else:\n",
    "        order = np.argpartition(-sims, top_k)[:top_k]\n",
    "        order = order[np.argsort(-sims[order])]\n",
    "\n",
    "    results: List[Tuple[str, str, float, Optional[int], Optional[List[str]]]] = []\n",
    "    for pos in order:\n",
    "        doc_idx = int(cand_idx[pos])\n",
    "        sim_val = float(sims[pos])\n",
    "        # Allow small negative similarities (cosine can be negative for normalized vectors)\n",
    "        # But prefer positive similarities, so we still filter out very negative ones\n",
    "        if sim_val < -0.01:  # Only filter out clearly negative similarities\n",
    "            continue\n",
    "        cluster_id: Optional[int] = None\n",
    "        cluster_topics_list: Optional[List[str]] = None\n",
    "        if cluster_labels is not None and doc_idx < cluster_labels.shape[0]:\n",
    "            cluster_id = int(cluster_labels[doc_idx])\n",
    "            if cluster_topics is not None:\n",
    "                topics = cluster_topics.get(cluster_id)\n",
    "                if topics is not None:\n",
    "                    cluster_topics_list = list(topics)\n",
    "        results.append(\n",
    "            (\n",
    "                str(doc_ids[doc_idx]),\n",
    "                str(doc_titles[doc_idx]),\n",
    "                sim_val,\n",
    "                cluster_id,\n",
    "                cluster_topics_list,\n",
    "            )\n",
    "        )\n",
    "    return results"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "results_md",
   "metadata": {},
   "source": [
    "## Result Processing\n",
    "\n",
    "Functions to save results to JSONL files and print them nicely."
   ]
  },
  {
   "cell_type": "code",
   "id": "results_code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T19:58:36.325853Z",
     "start_time": "2025-12-04T19:58:36.318417Z"
    }
   },
   "source": [
    "def load_raw_meta(need_ids: set) -> dict:\n",
    "    hit = {}\n",
    "    if not RAW_JSONL_PATH.exists():\n",
    "        print(\"raw file not found, skip extra fields\")\n",
    "        return hit\n",
    "    found = 0\n",
    "    target = len(need_ids)\n",
    "    with RAW_JSONL_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                obj = json.loads(line)\n",
    "            except Exception:\n",
    "                continue\n",
    "            pid = obj.get(\"id\")\n",
    "            if pid in need_ids:\n",
    "                hit[pid] = obj\n",
    "                found += 1\n",
    "                if found >= target:\n",
    "                    break\n",
    "    return hit\n",
    "\n",
    "def find_best_matching_topic(\n",
    "    paper_text: str, \n",
    "    topics: List[str], \n",
    "    vocab: Dict[str, int],\n",
    "    idf: np.ndarray\n",
    ") -> Optional[str]:\n",
    "\n",
    "    if not topics or not paper_text:\n",
    "        return None\n",
    "    \n",
    "    paper_preprocessed = preprocess_query(paper_text)\n",
    "    paper_vec = query_to_tfidf_vec(paper_preprocessed, vocab, idf, verbose=False)\n",
    "    \n",
    "    if paper_vec.sum() == 0:\n",
    "        return None\n",
    "    \n",
    "    topic_scores = []\n",
    "    \n",
    "    for topic in topics:\n",
    "        topic_preprocessed = preprocess_query(topic)\n",
    "        topic_vec = query_to_tfidf_vec(topic_preprocessed, vocab, idf, verbose=False)\n",
    "        \n",
    "        if topic_vec.sum() == 0:\n",
    "            continue\n",
    "        \n",
    "        similarity = (paper_vec @ topic_vec.T).toarray()[0, 0]\n",
    "        topic_scores.append((similarity, topic))\n",
    "    \n",
    "    if not topic_scores:\n",
    "        return None\n",
    "    \n",
    "    topic_scores.sort(reverse=True, key=lambda x: x[0])\n",
    "    best_topic = topic_scores[0][1]\n",
    "    if topic_scores[0][0] < 0.01:\n",
    "        return None\n",
    "    \n",
    "    return best_topic\n",
    "\n",
    "def save_results_jsonl(query: str, method: str, results: List[Tuple[str, str, float, Optional[int], Optional[List[str]]]], requested_top_k: Optional[int] = None) -> Path:\n",
    "    need_ids = {pid for (pid, _title, _s, _cluster, _topics) in results}\n",
    "    raw_meta = load_raw_meta(need_ids)\n",
    "    \n",
    " \n",
    "    vocab = json.loads(VOCAB_JSON.read_text(encoding=\"utf-8\"))\n",
    "    idf = np.load(IDF_NPY)\n",
    "\n",
    "    # output file path\n",
    "    ts = int(time.time())\n",
    "    if requested_top_k is not None:\n",
    "        out_path = OUT_DIR / f\"similarity_for_recommend_{method}_{ts}_topk{requested_top_k}.json\"\n",
    "    else:\n",
    "        out_path = OUT_DIR / f\"similarity_for_recommend_{method}_{ts}.json\"\n",
    "\n",
    "    with out_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        if not results:\n",
    "            # Save metadata even when no results found\n",
    "            empty_result = {\n",
    "                \"query\": query,\n",
    "                \"method\": method,\n",
    "                \"result_count\": 0,\n",
    "                \"timestamp\": ts,\n",
    "                \"message\": \"No results found. Query terms may not be in vocabulary.\"\n",
    "            }\n",
    "            f.write(json.dumps(empty_result, ensure_ascii=False) + \"\\n\")\n",
    "        else:\n",
    "            for rank, (pid, title, sc, cluster_id, cluster_topics_list) in enumerate(results, 1):\n",
    "                base = raw_meta.get(pid, {})\n",
    "                \n",
    "                # calculate the most matching topic and remove it from the list\n",
    "                filtered_topics = None\n",
    "                matched_topic = None\n",
    "                if cluster_topics_list:\n",
    "                    paper_title = base.get(\"title\", title)\n",
    "                    paper_abstract = base.get(\"abstract\", \"\")\n",
    "                    paper_text = f\"{paper_title} {paper_abstract}\"\n",
    "                    \n",
    "                    # use TF-IDF similarity to find the most matching topic\n",
    "                    matched_topic = find_best_matching_topic(paper_text, cluster_topics_list, vocab, idf)\n",
    "                    \n",
    "                    if matched_topic and matched_topic in cluster_topics_list:\n",
    "                        filtered_topics = [t for t in cluster_topics_list if t != matched_topic]\n",
    "                    else:\n",
    "                        filtered_topics = cluster_topics_list.copy()\n",
    "                \n",
    "                base.update({\n",
    "                    \"sim_score\": float(sc),\n",
    "                    \"score\": float(sc),\n",
    "                    \"similarity\": float(sc),\n",
    "                    \"rank\": rank,\n",
    "                    \"query\": query,\n",
    "                    \"method\": method,\n",
    "                    \"lsa_cluster_id\": int(cluster_id) if cluster_id is not None else None,\n",
    "                    \"topics\": filtered_topics,\n",
    "                    \"matched_topic\": matched_topic, \n",
    "                })\n",
    "                f.write(json.dumps(base, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    print(f\"saved to: {out_path}\")\n",
    "    return out_path\n",
    "\n",
    "def print_results(query: str, method: str, results: List[Tuple[str, str, float, Optional[int], Optional[List[str]]]]):\n",
    "    # simple pretty print\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"query: {query}\")\n",
    "    print(f\"model: {method}\")\n",
    "    if results:\n",
    "        print(f\"top {len(results)} here ↓\")\n",
    "    else:\n",
    "        print(f\"top 0 here ↓\")\n",
    "        print(f\"[error] No results found - query produced zero similarity scores\")\n",
    "        print(f\"[info] This happens when:\")\n",
    "        print(f\"       1. All query terms are missing from vocabulary\")\n",
    "        print(f\"       2. Query vector is zero (no matching terms)\")\n",
    "        print(f\"       3. Even with LSH, zero query vector cannot match any documents\")\n",
    "    print(\"=\" * 70)\n",
    "    for i, (pid, title, sc, cluster_id, cluster_topics_list) in enumerate(results, 1):\n",
    "        print(f\"{i:2d}. [{pid}] {title}\")\n",
    "        cluster_str = \"N/A\" if cluster_id is None else str(cluster_id)\n",
    "        print(f\"    score: {sc:.4f} | cluster: {cluster_str}\")\n",
    "        if cluster_topics_list:\n",
    "            pretty_topics = \", \".join(cluster_topics_list)\n",
    "            print(f\"    topics: {pretty_topics}\")\n",
    "    if not results:\n",
    "        print(\"hmm no hit, maybe try other words\")"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "interactive_md",
   "metadata": {},
   "source": [
    "## Interactive Search\n",
    "\n",
    "Use the cell below to run a search. Change the `query`, `top_k`, and `method` variables as needed.  \n",
    "Here, “topk” does not refer to the number of search results (currently defaulting to 100 papers), but rather the number of papers the user wishes to study.  \n",
    "We simply append this value to the filenames of the 100 paper collections. This allows it to be parsed during subsequent recommendation steps, determining the final number of papers recommended."
   ]
  },
  {
   "cell_type": "code",
   "id": "interactive_code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T20:07:15.098852Z",
     "start_time": "2025-12-04T20:07:04.641123Z"
    }
   },
   "source": [
    "# === Interactive Search ===\n",
    "\n",
    "query = \"I wish to study papers in the field of software engineering.\"  # Change this query\n",
    "top_k = 10\n",
    "method = \"lsa_lsh\"  # Options: \"tfidf\", \"lsa\", \"lsa_lsh\"\n",
    "\n",
    "print(f\"[info] query  = {query}\")\n",
    "print(f\"[info] top_k = {top_k}\")\n",
    "print(f\"[info] method = {method}\")\n",
    "\n",
    "t0 = time.time()\n",
    "search_k = max(100, top_k)\n",
    "\n",
    "if method == \"tfidf\":\n",
    "    results = search_tfidf(query, search_k)\n",
    "elif method == \"lsa\":\n",
    "    results = search_lsa(query, search_k)\n",
    "else:  # lsa_lsh\n",
    "    results = search_lsa_lsh(query, search_k)\n",
    "\n",
    "dt = time.time() - t0\n",
    "\n",
    "print_results(query, method, results)\n",
    "out_file = save_results_jsonl(query, method, results, requested_top_k=top_k)\n",
    "\n",
    "print(f\"[ok] Saved results to: {out_file}\")\n",
    "print(f\"[ok] Time spent: {dt:.2f}s\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] query  = I wish to study papers in the field of software engineering.\n",
      "[info] top_k = 10\n",
      "[info] method = lsa_lsh\n",
      "[info] Query tokens found in vocabulary: ['wish', 'softwar', 'engin']\n",
      "[info] Query tokens not in vocabulary: ['paper']\n",
      "\n",
      "======================================================================\n",
      "query: I wish to study papers in the field of software engineering.\n",
      "model: lsa_lsh\n",
      "top 100 here ↓\n",
      "======================================================================\n",
      " 1. [1702.01715] Software Engineering at Google\n",
      "    score: 0.8974 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      " 2. [1812.01791] A Formal Method for Mapping Software Engineering Practices to Essence\n",
      "    score: 0.8048 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      " 3. [2206.09303] The Framework For The Discipline Of Software Engineering in Connection\n",
      "  to Information Technology Discipline\n",
      "    score: 0.7735 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      " 4. [1802.02517] Blueprint and Evaluation Instruments for a Course on Software\n",
      "  Engineering for Sustainability\n",
      "    score: 0.7696 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      " 5. [2110.02251] An Exploration of the Mentorship Needs of Research Software Engineers\n",
      "    score: 0.7350 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      " 6. [2105.00272] Benchmarking as Empirical Standard in Software Engineering Research\n",
      "    score: 0.7340 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      " 7. [2403.08085] Lessons from a Pioneering Software Engineering Environment: Design\n",
      "  Principles of Software through Pictures\n",
      "    score: 0.7275 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      " 8. [2002.10163] Software Engineering Timeline: major areas of interest and\n",
      "  multidisciplinary trends\n",
      "    score: 0.7145 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      " 9. [2206.05397] Software Engineering in Australasia\n",
      "    score: 0.7115 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "10. [2207.12578] A Retrospective on ICSE 2022\n",
      "    score: 0.6984 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "11. [1712.00061] Agile Software Engineering and Systems Engineering at SKA Scale\n",
      "    score: 0.6900 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "12. [2308.07796] Research Software Engineering in 2030\n",
      "    score: 0.6848 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "13. [2010.03165] Questions for Data Scientists in Software Engineering: A Replication\n",
      "    score: 0.6838 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "14. [1511.08845] Psychological Types of Brazilian Software Engineering Students\n",
      "    score: 0.6821 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "15. [2304.06539] Taxing Collaborative Software Engineering\n",
      "    score: 0.6813 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "16. [1802.06321] The Dangerous Dogmas of Software Engineering\n",
      "    score: 0.6808 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "17. [2303.07467] Battle of the Blocs: Quantity and Quality of Software Engineering\n",
      "  Research by Origin\n",
      "    score: 0.6800 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "18. [1201.5735] Deconcentration of Attention: Addressing the Complexity of Software\n",
      "  Engineering\n",
      "    score: 0.6774 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "19. [1712.05078] Fourteen Years of Software Engineering at ETH Zurich\n",
      "    score: 0.6771 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "20. [1805.02742] Fifty Years of Software Engineering - or - The View from Garmisch\n",
      "    score: 0.6737 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "21. [1904.11540] First things first: If software engineering is the solution, then what\n",
      "  is the problem?\n",
      "    score: 0.6734 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "22. [0911.3306] Software Engineering Education by Example\n",
      "    score: 0.6717 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "23. [2112.06617] (R)SE challenges in HPC\n",
      "    score: 0.6702 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "24. [2010.07381] How Research Software Engineers Can Support Scientific Software\n",
      "    score: 0.6679 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "25. [1904.02465] The Systems Approach to Change and the Agile Software Development\n",
      "  Context\n",
      "    score: 0.6661 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "26. [1209.0948] Teaching cloud computing: a software engineering perspective\n",
      "    score: 0.6626 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "27. [2301.08923] The Risk-Taking Software Engineer: A Framed Portrait\n",
      "    score: 0.6526 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "28. [2011.01590] Turning Software Engineers into AI Engineers\n",
      "    score: 0.6524 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "29. [0711.0538] Spreadsheet Engineering: A Research Framework\n",
      "    score: 0.6455 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "30. [2103.01880] Sustaining Research Software via Research Software Engineers and\n",
      "  Professional Associations\n",
      "    score: 0.6449 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "31. [2010.04660] Research, Develop, Deploy: Building a Full Spectrum Software Engineering\n",
      "  and Research Department\n",
      "    score: 0.6441 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "32. [1912.11512] The Evolution of Empirical Methods in Software Engineering\n",
      "    score: 0.6431 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "33. [1808.02723] Essencery - A Tool for Essentializing Software Engineering Practices\n",
      "    score: 0.6431 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "34. [2207.01254] The Present and Future of Bots in Software Engineering\n",
      "    score: 0.6412 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "35. [2403.16827] Seeking Enlightenment: Incorporating Evidence-Based Practice Techniques\n",
      "  in a Research Software Engineering Team\n",
      "    score: 0.6411 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "36. [2309.04142] Trustworthy and Synergistic Artificial Intelligence for Software\n",
      "  Engineering: Vision and Roadmaps\n",
      "    score: 0.6400 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "37. [2103.01309] Investigating the potential impact of values on requirements and\n",
      "  software engineering\n",
      "    score: 0.6391 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "38. [2406.03342] Understanding and measuring software engineer behavior: What can we\n",
      "  learn from the behavioral sciences?\n",
      "    score: 0.6375 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "39. [2309.13358] Towards Quantum Software Requirements Engineering\n",
      "    score: 0.6336 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "40. [2110.12937] Improving Software Engineering Research through Experimentation\n",
      "  Workbenches\n",
      "    score: 0.6328 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "41. [2407.08823] With Great Power Comes Great Responsibility: The Role of Software\n",
      "  Engineers\n",
      "    score: 0.6317 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "42. [1109.3444] Large-scale Complex IT Systems\n",
      "    score: 0.6304 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "43. [1904.09820] On Gender, Ethnicity, and Culture in Empirical Software Engineering\n",
      "  Research\n",
      "    score: 0.6297 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "44. [2305.04349] Documenting Bioinformatics Software Via Reverse Engineering\n",
      "    score: 0.6295 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "45. [2103.11249] SELM: Software Engineering of Machine Learning Models\n",
      "    score: 0.6275 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "46. [1810.01904] RPSE: Reification as Paradigm of Software Engineering\n",
      "    score: 0.6268 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "47. [2002.10835] Software Engineering und Software Engineering Forschung im Zeitalter der\n",
      "  Digitalisierung\n",
      "    score: 0.6267 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "48. [1703.00619] Reflections on Cyberethics Education for Millennial Software Engineers\n",
      "    score: 0.6264 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "49. [2411.17981] Engineering Trustworthy Software: A Mission for LLMs\n",
      "    score: 0.6234 | cluster: 8\n",
      "    topics: Large Language Models, Prompting & Alignment\n",
      "50. [1112.4016] The Study and Approach of Software Re-Engineering\n",
      "    score: 0.6230 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "51. [1801.10241] Data-Driven Search-based Software Engineering\n",
      "    score: 0.6209 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "52. [2411.09467] The Perceptions of Software Engineers Concerning the Utilization of Bots\n",
      "  in the OSS Development Process: An Exploratory Survey\n",
      "    score: 0.6205 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "53. [2407.04596] Teaching and Learning Ethnography for Software Engineering Contexts\n",
      "    score: 0.6202 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "54. [2407.08176] Foundation Model Engineering: Engineering Foundation Models Just as\n",
      "  Engineering Software\n",
      "    score: 0.6202 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "55. [1904.08239] Happiness and the productivity of software engineers\n",
      "    score: 0.6183 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "56. [2405.01546] It Will Never Work in Theory\n",
      "    score: 0.6179 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "57. [2303.17271] What Practitioners Really Think About Continuous Software Engineering: A\n",
      "  Taxonomy of Challenges\n",
      "    score: 0.6172 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "58. [1104.5387] Model based system engineering approach of a lightweight embedded TCP/IP\n",
      "    score: 0.6166 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "59. [1809.08827] The Essence Theory of Software Engineering - Large-Scale Classroom\n",
      "  Experiences from 450+ Software Engineering BSc Students\n",
      "    score: 0.6162 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "60. [2201.04007] Building Bridges: Establishing a Dialogue Between Software Engineering\n",
      "  Research and Computational Science\n",
      "    score: 0.6159 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "61. [1911.04016] Challenges for Inclusion in Software Engineering: The Case of the\n",
      "  Emerging Papua New Guinean Society\n",
      "    score: 0.6152 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "62. [1307.2075] A Web-based modeling tool for the SEMAT Essence theory of Software\n",
      "  Engineering\n",
      "    score: 0.6148 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "63. [2003.00463] Experience in engineering of scientific software: The case of an\n",
      "  optimization software for oil pipelines\n",
      "    score: 0.6146 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "64. [2306.06834] Motivational models for validating agile requirements in Software\n",
      "  Engineering subjects\n",
      "    score: 0.6144 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "65. [0806.2730] A Process Algebra Software Engineering Environment\n",
      "    score: 0.6136 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "66. [2207.00892] Software Engineering Process and Methodology in Blockchain-Oriented\n",
      "  Software Development: A Systematic Study\n",
      "    score: 0.6132 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "67. [2009.09295] Software Engineering Standards for Epidemiological Modeling\n",
      "    score: 0.6129 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "68. [2010.08538] Underpinning Theories of Software Engineering: Dynamism in Physical\n",
      "  Sources of the Shannon Weaver Communication Model\n",
      "    score: 0.6122 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "69. [1508.02031] What Is Software Engineering?\n",
      "    score: 0.6111 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "70. [2212.00619] Automated Quantum Software Engineering: why? what? how?\n",
      "    score: 0.6108 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "71. [1911.09971] Four presumed gaps in the software engineering research community's\n",
      "  knowledge\n",
      "    score: 0.6104 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "72. [cs/0402036] Towards a Model-Based Framework for Integrating Usability and Software\n",
      "  Engineering Life Cycles\n",
      "    score: 0.6097 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "73. [1807.04072] Building a Sustainable Structure for Research Software Engineering\n",
      "  Activities\n",
      "    score: 0.6066 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "74. [1809.01940] Standards of Validity and the Validity of Standards in Behavioral\n",
      "  Software Engineering Research: The Perspective of Psychological Test Theory\n",
      "    score: 0.6053 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "75. [2201.04010] Working in Harmony: Towards Integrating RSEs into Multi-Disciplinary CSE\n",
      "  Teams\n",
      "    score: 0.6049 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "76. [1712.02448] Towards Methods for Model-Based Software Development\n",
      "    score: 0.6042 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "77. [1503.03584] Human Factors in Software Reliability Engineering\n",
      "    score: 0.6042 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "78. [2006.04967] Summarising Big Data: Common GitHub Dataset for Software Engineering\n",
      "  Challenges\n",
      "    score: 0.6034 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "79. [2308.12816] Software Startups -- A Research Agenda\n",
      "    score: 0.6034 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "80. [1407.5701] Sustainable Software Ecosystems: Software Engineers, Domain Scientists,\n",
      "  and Engineers Collaborating for Science\n",
      "    score: 0.6031 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "81. [1903.00732] Research Software Development & Management in Universities: Case Studies\n",
      "  from Manchester's RSDS Group, Illinois' NCSA, and Notre Dame's CRC\n",
      "    score: 0.6020 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "82. [2212.04877] Industry Best Practices in Robotics Software Engineering\n",
      "    score: 0.6020 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "83. [2410.13110] Deep Learning-based Software Engineering: Progress, Challenges, and\n",
      "  Opportunities\n",
      "    score: 0.6018 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "84. [1511.04411] Personality Profiles of Software Engineers and Their Software Quality\n",
      "  Preferences\n",
      "    score: 0.6013 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "85. [2002.01035] The Four Pillars of Research Software Engineering\n",
      "    score: 0.6006 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "86. [1809.00039] Total Recall, Language Processing, and Software Engineering\n",
      "    score: 0.6002 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "87. [2109.04738] On the validity of pre-trained transformers for natural language\n",
      "  processing in the software engineering domain\n",
      "    score: 0.5986 | cluster: 34\n",
      "    topics: Natural Language Processing, Language Modeling\n",
      "88. [2201.01359] Software and Security Engineering in Digital Transformation\n",
      "    score: 0.5978 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "89. [2004.06174] Understanding What Software Engineers Are Working on -- The Work-Item\n",
      "  Prediction Challenge\n",
      "    score: 0.5970 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "90. [1410.4078] Softwaretechnische Absicherung intelligenter Systeme im Fahrzeug\n",
      "    score: 0.5969 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "91. [2406.02412] FAIRSECO: An Extensible Framework for Impact Measurement of Research\n",
      "  Software\n",
      "    score: 0.5966 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "92. [2401.09608] Hidden Populations in Software Engineering: Challenges, Lessons Learned,\n",
      "  and Opportunities\n",
      "    score: 0.5938 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "93. [1812.09261] On Testing Quantum Programs\n",
      "    score: 0.5932 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "94. [1903.06039] What Makes Research Software Sustainable? An Interview Study With\n",
      "  Research Software Engineers\n",
      "    score: 0.5931 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "95. [1605.01097] Reliability Testing Strategy - Reliability in Software Engineering\n",
      "    score: 0.5929 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "96. [1412.4648] A Survey of Software Engineering Practices in Turkey (extended version)\n",
      "    score: 0.5922 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "97. [1305.6045] The Dynamics of Creativity in Software Development\n",
      "    score: 0.5921 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "98. [2405.05017] 6G Software Engineering: A Systematic Mapping Study\n",
      "    score: 0.5908 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "99. [1306.2414] Action Research Can Swing the Balance in Experimental Software\n",
      "  Engineering\n",
      "    score: 0.5906 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "100. [2402.08505] Q-COSMIC: Quantum Software Metrics Based on COSMIC (ISO/IEC19761)\n",
      "    score: 0.5878 | cluster: 22\n",
      "    topics: General Algorithms, Applied Machine Learning\n",
      "saved to: /Users/jasonh/Desktop/02807/PaperTrail/data/similarity_results/similarity_results_v2/similarity_for_recommend_lsa_lsh_1764878834_topk10.json\n",
      "[ok] Saved results to: /Users/jasonh/Desktop/02807/PaperTrail/data/similarity_results/similarity_results_v2/similarity_for_recommend_lsa_lsh_1764878834_topk10.json\n",
      "[ok] Time spent: 5.39s\n"
     ]
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
