{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b9a1d9d",
   "metadata": {},
   "source": [
    "# ArXiv Metadata Analysis\n",
    "\n",
    "This notebook analyzes the content and format of the `arxiv-metadata-oai-snapshot.json` file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4ca5bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 4.54 GB\n",
      "File size: 4649.80 MB\n",
      "File size: 4,875,669,363 bytes\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up the file path\n",
    "file_path = \"/work3/s242644/PaperTrail/arxiv-metadata-oai-snapshot.json\"\n",
    "\n",
    "# Check file size and basic info\n",
    "file_size = os.path.getsize(file_path)\n",
    "print(f\"File size: {file_size / (1024**3):.2f} GB\")\n",
    "print(f\"File size: {file_size / (1024**2):.2f} MB\")\n",
    "print(f\"File size: {file_size:,} bytes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1373131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of papers: 2,840,638\n",
      "Average size per paper: 1716 bytes\n"
     ]
    }
   ],
   "source": [
    "# Count total number of papers\n",
    "with open(file_path, 'r') as f:\n",
    "    line_count = sum(1 for line in f)\n",
    "\n",
    "print(f\"Total number of papers: {line_count:,}\")\n",
    "print(f\"Average size per paper: {file_size / line_count:.0f} bytes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea1a317e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual paper structure analysis:\n",
      "==================================================\n",
      "\n",
      "First paper keys: ['id', 'submitter', 'authors', 'title', 'comments', 'journal-ref', 'doi', 'report-no', 'categories', 'license', 'abstract', 'versions', 'update_date', 'authors_parsed']\n",
      "Number of fields: 14\n",
      "\n",
      "Detailed structure of first paper:\n",
      "----------------------------------------\n",
      "id (str): 0704.0001\n",
      "submitter (str): Pavel Nadolsky\n",
      "authors (str): C. Bal\\'azs, E. L. Berger, P. M. Nadolsky, C.-P. Yuan\n",
      "title (str): Calculation of prompt diphoton production cross sections at Tevatron and\n",
      "  LHC energies\n",
      "comments (str): 37 pages, 15 figures; published version\n",
      "journal-ref (str): Phys.Rev.D76:013009,2007\n",
      "doi (str): 10.1103/PhysRevD.76.013009\n",
      "report-no (str): ANL-HEP-PR-07-12\n",
      "categories (str): hep-ph\n",
      "license (NoneType): None\n",
      "abstract (str):   A fully differential calculation in perturbative quantum chromodynamics is\n",
      "presented for the produ...\n",
      "versions (list): [{'version': 'v1', 'created': 'Mon, 2 Apr 2007 19:18:42 GMT'}, {'version': 'v2', 'created': 'Tue, 24 Jul 2007 20:10:27 GMT'}]\n",
      "update_date (str): 2008-11-26\n",
      "authors_parsed (list): [['Balázs', 'C.', ''], ['Berger', 'E. L.', ''], ['Nadolsky', 'P. M.', ''], ['Yuan', 'C. -P.', '']]\n",
      "\n",
      "Sample of all papers structure:\n",
      "----------------------------------------\n",
      "\n",
      "Paper 1 keys: ['id', 'submitter', 'authors', 'title', 'comments', 'journal-ref', 'doi', 'report-no', 'categories', 'license', 'abstract', 'versions', 'update_date', 'authors_parsed']\n",
      "Paper 1 ID: 0704.0001\n",
      "Paper 1 title: Calculation of prompt diphoton production cross se...\n",
      "\n",
      "Paper 2 keys: ['id', 'submitter', 'authors', 'title', 'comments', 'journal-ref', 'doi', 'report-no', 'categories', 'license', 'abstract', 'versions', 'update_date', 'authors_parsed']\n",
      "Paper 2 ID: 0704.0002\n",
      "Paper 2 title: Sparsity-certifying Graph Decompositions...\n",
      "\n",
      "Paper 3 keys: ['id', 'submitter', 'authors', 'title', 'comments', 'journal-ref', 'doi', 'report-no', 'categories', 'license', 'abstract', 'versions', 'update_date', 'authors_parsed']\n",
      "Paper 3 ID: 0704.0003\n",
      "Paper 3 title: The evolution of the Earth-Moon system based on th...\n",
      "\n",
      "Paper 4 keys: ['id', 'submitter', 'authors', 'title', 'comments', 'journal-ref', 'doi', 'report-no', 'categories', 'license', 'abstract', 'versions', 'update_date', 'authors_parsed']\n",
      "Paper 4 ID: 0704.0004\n",
      "Paper 4 title: A determinant of Stirling cycle numbers counts unl...\n",
      "\n",
      "Paper 5 keys: ['id', 'submitter', 'authors', 'title', 'comments', 'journal-ref', 'doi', 'report-no', 'categories', 'license', 'abstract', 'versions', 'update_date', 'authors_parsed']\n",
      "Paper 5 ID: 0704.0005\n",
      "Paper 5 title: From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\alpha...\n"
     ]
    }
   ],
   "source": [
    "# Load and examine a sample of papers\n",
    "sample_papers = []\n",
    "with open(file_path, 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= 10:  # Load first 10 papers\n",
    "            break\n",
    "        sample_papers.append(json.loads(line.strip()))\n",
    "\n",
    "print(\"Sample paper structure:\")\n",
    "print(\"=\" * 50)\n",
    "for i, paper in enumerate(sample_papers[:3]):\n",
    "    print(f\"\\nPaper {i+1}:\")\n",
    "    print(f\"ID: {paper['id']}\")\n",
    "    print(f\"Title: {paper['title'][:100]}...\")\n",
    "    print(f\"Authors: {paper['authors'][:100]}...\")\n",
    "    print(f\"Categories: {paper['categories']}\")\n",
    "    print(f\"Abstract length: {len(paper['abstract'])} characters\")\n",
    "    print(f\"Versions: {len(paper['versions'])}\")\n",
    "    print(f\"Update date: {paper['update_date']}\")\n",
    "    print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89129a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consistency check across papers:\n",
      "==================================================\n",
      "All unique keys found: ['abstract', 'authors', 'authors_parsed', 'categories', 'comments', 'doi', 'id', 'journal-ref', 'license', 'report-no', 'submitter', 'title', 'update_date', 'versions']\n",
      "Total unique keys: 14\n",
      "\n",
      "Key presence across papers:\n",
      "report-no: present in 5/5 papers\n",
      "categories: present in 5/5 papers\n",
      "comments: present in 5/5 papers\n",
      "authors: present in 5/5 papers\n",
      "title: present in 5/5 papers\n",
      "authors_parsed: present in 5/5 papers\n",
      "license: present in 5/5 papers\n",
      "versions: present in 5/5 papers\n",
      "journal-ref: present in 5/5 papers\n",
      "abstract: present in 5/5 papers\n",
      "update_date: present in 5/5 papers\n",
      "doi: present in 5/5 papers\n",
      "submitter: present in 5/5 papers\n",
      "id: present in 5/5 papers\n"
     ]
    }
   ],
   "source": [
    "# Analyze the complete structure of one paper\n",
    "print(\"Complete structure of a single paper:\")\n",
    "print(\"=\" * 50)\n",
    "sample_paper = sample_papers[0]\n",
    "for key, value in sample_paper.items():\n",
    "    if isinstance(value, str) and len(value) > 100:\n",
    "        print(f\"{key}: {value[:100]}... (length: {len(value)})\")\n",
    "    elif isinstance(value, list):\n",
    "        print(f\"{key}: {value} (length: {len(value)})\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "860d8e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing actual data structure...\n",
      "==================================================\n",
      "All possible keys in dataset: ['abstract', 'authors', 'authors_parsed', 'categories', 'comments', 'doi', 'id', 'journal-ref', 'license', 'report-no', 'submitter', 'title', 'update_date', 'versions']\n",
      "\n",
      "Data types for each key:\n",
      "report-no: {'str', 'NoneType'}\n",
      "categories: {'str'}\n",
      "comments: {'str', 'NoneType'}\n",
      "authors: {'str'}\n",
      "title: {'str'}\n",
      "authors_parsed: {'list'}\n",
      "license: {'str', 'NoneType'}\n",
      "versions: {'list'}\n",
      "journal-ref: {'str', 'NoneType'}\n",
      "abstract: {'str'}\n",
      "update_date: {'str'}\n",
      "doi: {'str', 'NoneType'}\n",
      "submitter: {'str'}\n",
      "id: {'str'}\n",
      "\n",
      "Null/None value analysis:\n",
      "report-no: 92/100 papers have null/empty values\n",
      "categories: 0/100 papers have null/empty values\n",
      "comments: 13/100 papers have null/empty values\n",
      "authors: 0/100 papers have null/empty values\n",
      "title: 0/100 papers have null/empty values\n",
      "authors_parsed: 0/100 papers have null/empty values\n",
      "license: 87/100 papers have null/empty values\n",
      "versions: 0/100 papers have null/empty values\n",
      "journal-ref: 48/100 papers have null/empty values\n",
      "abstract: 0/100 papers have null/empty values\n",
      "update_date: 0/100 papers have null/empty values\n",
      "doi: 50/100 papers have null/empty values\n",
      "submitter: 0/100 papers have null/empty values\n",
      "id: 0/100 papers have null/empty values\n"
     ]
    }
   ],
   "source": [
    "# Analyze categories distribution\n",
    "categories = []\n",
    "abstract_lengths = []\n",
    "years = []\n",
    "\n",
    "print(\"Analyzing categories and other metadata...\")\n",
    "with open(file_path, 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= 1000:  # Analyze first 1000 papers for efficiency\n",
    "            break\n",
    "        paper = json.loads(line.strip())\n",
    "        \n",
    "        # Extract categories\n",
    "        if paper['categories']:\n",
    "            categories.extend(paper['categories'].split())\n",
    "        \n",
    "        # Extract abstract length\n",
    "        abstract_lengths.append(len(paper['abstract']))\n",
    "        \n",
    "        # Extract year from update_date\n",
    "        if paper['update_date']:\n",
    "            try:\n",
    "                year = int(paper['update_date'].split('-')[0])\n",
    "                years.append(year)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "print(f\"Analyzed {min(1000, line_count)} papers\")\n",
    "print(f\"Total category mentions: {len(categories)}\")\n",
    "print(f\"Unique categories: {len(set(categories))}\")\n",
    "print(f\"Average abstract length: {sum(abstract_lengths)/len(abstract_lengths):.0f} characters\")\n",
    "print(f\"Year range: {min(years)} - {max(years)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2971700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data from first 3 papers:\n",
      "==================================================\n",
      "\n",
      "--- Paper 1 ---\n",
      "id: 0704.0001\n",
      "submitter: Pavel Nadolsky\n",
      "authors: C. Bal\\'azs, E. L. Berger, P. M. Nadolsky, C.-P. Yuan\n",
      "title: Calculation of prompt diphoton production cross sections at Tevatron and\n",
      "  LHC e...\n",
      "comments: 37 pages, 15 figures; published version\n",
      "journal-ref: Phys.Rev.D76:013009,2007\n",
      "doi: 10.1103/PhysRevD.76.013009\n",
      "report-no: ANL-HEP-PR-07-12\n",
      "categories: hep-ph\n",
      "license: None\n",
      "abstract:   A fully differential calculation in perturbative quantum chromodynamics is\n",
      "pre...\n",
      "versions: [{'version': 'v1', 'created': 'Mon, 2 Apr 2007 19:18:42 GMT'}, {'version': 'v2', 'created': 'Tue, 24 Jul 2007 20:10:27 GMT'}]\n",
      "update_date: 2008-11-26\n",
      "authors_parsed: [['Balázs', 'C.', ''], ['Berger', 'E. L.', ''], ['Nadolsky', 'P. M.', '']]... (length: 4)\n",
      "------------------------------\n",
      "\n",
      "--- Paper 2 ---\n",
      "id: 0704.0002\n",
      "submitter: Louis Theran\n",
      "authors: Ileana Streinu and Louis Theran\n",
      "title: Sparsity-certifying Graph Decompositions\n",
      "comments: To appear in Graphs and Combinatorics\n",
      "journal-ref: None\n",
      "doi: None\n",
      "report-no: None\n",
      "categories: math.CO cs.CG\n",
      "license: http://arxiv.org/licenses/nonexclusive-distrib/1.0/\n",
      "abstract:   We describe a new algorithm, the $(k,\\ell)$-pebble game with colors, and use\n",
      "i...\n",
      "versions: [{'version': 'v1', 'created': 'Sat, 31 Mar 2007 02:26:18 GMT'}, {'version': 'v2', 'created': 'Sat, 13 Dec 2008 17:26:00 GMT'}]\n",
      "update_date: 2008-12-13\n",
      "authors_parsed: [['Streinu', 'Ileana', ''], ['Theran', 'Louis', '']]\n",
      "------------------------------\n",
      "\n",
      "--- Paper 3 ---\n",
      "id: 0704.0003\n",
      "submitter: Hongjun Pan\n",
      "authors: Hongjun Pan\n",
      "title: The evolution of the Earth-Moon system based on the dark matter field\n",
      "  fluid mo...\n",
      "comments: 23 pages, 3 figures\n",
      "journal-ref: None\n",
      "doi: None\n",
      "report-no: None\n",
      "categories: physics.gen-ph\n",
      "license: None\n",
      "abstract:   The evolution of Earth-Moon system is described by the dark matter field\n",
      "fluid...\n",
      "versions: [{'version': 'v1', 'created': 'Sun, 1 Apr 2007 20:46:54 GMT'}, {'version': 'v2', 'created': 'Sat, 8 Dec 2007 23:47:24 GMT'}, {'version': 'v3', 'created': 'Sun, 13 Jan 2008 00:36:28 GMT'}]\n",
      "update_date: 2008-01-13\n",
      "authors_parsed: [['Pan', 'Hongjun', '']]\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "category_counts = Counter(categories)\n",
    "print(\"\\nTop 20 categories:\")\n",
    "print(\"=\" * 30)\n",
    "for category, count in category_counts.most_common(20):\n",
    "    print(f\"{category}: {count}\")\n",
    "\n",
    "# Year distribution\n",
    "year_counts = Counter(years)\n",
    "print(f\"\\nYear distribution (first 10 years):\")\n",
    "print(\"=\" * 30)\n",
    "for year in sorted(year_counts.keys())[:10]:\n",
    "    print(f\"{year}: {year_counts[year]} papers\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
