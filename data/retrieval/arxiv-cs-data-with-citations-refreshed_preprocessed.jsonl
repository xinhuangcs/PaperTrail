{"id": "1601.00796", "submitter": "Mohammad Khodaei", "authors": "Mohammad Khodaei and Panos Papadimitratos", "title": "The Key to Intelligent Transportation: Identity and Credential\n  Management in Vehicular Communication Systems", "comments": "6 pages, 2 figures, IEEE Vehicular Technology Magazine, Volume:10,\n  Issue: 4", "journal-ref": null, "doi": "10.1109/MVT.2015.2479367", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicular Communication (VC) systems will greatly enhance intelligent\ntransportation systems. But their security and the protection of their users'\nprivacy are a prerequisite for deployment. Efforts in industry and academia\nbrought forth a multitude of diverse proposals. These have now converged to a\ncommon view, notably on the design of a security infrastructure, a Vehicular\nPublic Key Infrastructure (VPKI) that shall enable secure conditionally\nanonymous VC. Standardization efforts and industry readiness to adopt this\napproach hint to its maturity. However, there are several open questions\nremaining, and it is paramount to have conclusive answers before deployment. In\nthis article, we distill and critically survey the state of the art for\nidentity and credential management in VC systems, and we sketch a roadmap for\naddressing a set of critical remaining security and privacy challenges.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 11:22:12 GMT"}, {"version": "v2", "created": "Thu, 22 Sep 2016 15:17:30 GMT"}, {"version": "v3", "created": "Wed, 4 Jan 2017 16:00:37 GMT"}], "update_date": "2017-01-05", "authors_parsed": [["Khodaei", "Mohammad", ""], ["Papadimitratos", "Panos", ""]], "citation_count": 70, "citation_status": "ok_openalex_doi", "processed_content": "the key to intellig transport ident and credenti manag in vehicular commun system vehicular commun vc system will greatli enhanc intellig transport system but their secur and the protect of their user privaci are a prerequisit for deploy effort in industri and academia brought forth a multitud of divers propos these have now converg to a common view notabl on the design of a secur infrastructur a vehicular public key infrastructur vpki that shall enabl secur condit anonym vc standard effort and industri readi to adopt thi approach hint to it matur howev there are sever open question remain and it is paramount to have conclus answer befor deploy in thi articl we distil and critic survey the state of the art for ident and credenti manag in vc system and we sketch a roadmap for address a set of critic remain secur and privaci challeng"}
{"id": "1601.00797", "submitter": "Florian Heinrichs", "authors": "Holger Dette, Katrin Kettelhake, Kirsten Schorning, Weng Kee Wong,\n  Frank Bretz", "title": "Optimal designs for active controlled dose finding trials with\n  efficacy-toxicity outcomes", "comments": "Keywords and Phrases: Active controlled trials, dose finding, optimal\n  design, admissible design, Emax model, Equivalence theorem, Particle swarm\n  optimization, Tchebycheff system", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonlinear regression models addressing both efficacy and toxicity outcomes\nare increasingly used in dose-finding trials, such as in pharmaceutical drug\ndevelopment. However, research on related experimental design problems for\ncorresponding active controlled trials is still scarce. In this paper we derive\noptimal designs to estimate efficacy and toxicity in an active controlled\nclinical dose finding trial when the bivariate continuous outcomes are modeled\neither by polynomials up to degree 2, the Michaelis- Menten model, the Emax\nmodel, or a combination thereof. We determine upper bounds on the number of\ndifferent doses levels required for the optimal design and provide conditions\nunder which the boundary points of the design space are included in the optimal\ndesign. We also provide an analytical description of the minimally supported\n$D$-optimal designs and show that they do not depend on the correlation between\nthe bivariate outcomes. We illustrate the proposed methods with numerical\nexamples and demonstrate the advantages of the $D$-optimal design for a trial,\nwhich has recently been considered in the literature.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 11:32:11 GMT"}], "update_date": "2016-01-06", "authors_parsed": [["Dette", "Holger", ""], ["Kettelhake", "Katrin", ""], ["Schorning", "Kirsten", ""], ["Wong", "Weng Kee", ""], ["Bretz", "Frank", ""]], "citation_count": 0, "citation_status": "ok_openalex_title", "processed_content": "optim design for activ control dose find trial with efficaci toxic outcom nonlinear regress model address both efficaci and toxic outcom are increasingli use in dose find trial such as in pharmaceut drug develop howev research on relat experiment design problem for correspond activ control trial is still scarc in thi paper we deriv optim design to estim efficaci and toxic in an activ control clinic dose find trial when the bivari continu outcom are model either by polynomi up to degre 2 the micha menten model the emax model or a combin thereof we determin upper bound on the number of differ dose level requir for the optim design and provid condit under which the boundari point of the design space are includ in the optim design we also provid an analyt descript of the minim support d optim design and show that they do not depend on the correl between the bivari outcom we illustr the propos method with numer exampl and demonstr the advantag of the d optim design for a trial which ha recent been consid in the literatur"}
{"id": "1601.00815", "submitter": "Jana Jankova", "authors": "Jana Jankova and Sara van de Geer", "title": "Semi-parametric efficiency bounds for high-dimensional models", "comments": "68 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asymptotic lower bounds for estimation play a fundamental role in assessing\nthe quality of statistical procedures. In this paper we propose a framework for\nobtaining semi-parametric efficiency bounds for sparse high-dimensional models,\nwhere the dimension of the parameter is larger than the sample size. We adopt a\nsemi-parametric point of view: we concentrate on one dimensional functions of a\nhigh-dimensional parameter. We follow two different approaches to reach the\nlower bounds: asymptotic Cram\\'er-Rao bounds and Le Cam's type of analysis.\nBoth these approaches allow us to define a class of asymptotically unbiased or\n\"regular\" estimators for which a lower bound is derived. Consequently, we show\nthat certain estimators obtained by de-sparsifying (or de-biasing) an\n$\\ell_1$-penalized M-estimator are asymptotically unbiased and achieve the\nlower bound on the variance: thus in this sense they are asymptotically\nefficient. The paper discusses in detail the linear regression model and the\nGaussian graphical model.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 12:50:05 GMT"}, {"version": "v2", "created": "Wed, 8 Jun 2016 16:47:30 GMT"}, {"version": "v3", "created": "Fri, 4 Aug 2017 13:10:07 GMT"}, {"version": "v4", "created": "Thu, 12 Oct 2017 20:43:50 GMT"}], "update_date": "2017-10-16", "authors_parsed": [["Jankova", "Jana", ""], ["van de Geer", "Sara", ""]], "citation_count": 6, "citation_status": "ok_openalex_title", "processed_content": "semi parametr effici bound for high dimension model asymptot lower bound for estim play a fundament role in assess the qualiti of statist procedur in thi paper we propos a framework for obtain semi parametr effici bound for spars high dimension model where the dimens of the paramet is larger than the sampl size we adopt a semi parametr point of view we concentr on one dimension function of a high dimension paramet we follow two differ approach to reach the lower bound asymptot cram er rao bound and le cam s type of analysi both these approach allow us to defin a class of asymptot unbias or regular estim for which a lower bound is deriv consequ we show that certain estim obtain by de sparsifi or de bias an ell_1 penal m estim are asymptot unbias and achiev the lower bound on the varianc thu in thi sens they are asymptot effici the paper discuss in detail the linear regress model and the gaussian graphic model"}
{"id": "1601.00816", "submitter": "Pierre-Yves Oudeyer", "authors": "Pierre-Yves Oudeyer (Flowers)", "title": "Open challenges in understanding development and evolution of speech\n  forms: The roles of embodied self-organization, motivation and active\n  exploration", "comments": null, "journal-ref": "Journal of Phonetics, Elsevier, 2015, 53, pp.5", "doi": "10.1016/j.wocn.2015.09.001", "report-no": null, "categories": "cs.AI cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article discusses open scientific challenges for understanding\ndevelopment and evolution of speech forms, as a commentary to Moulin-Frier et\nal. (Moulin-Frier et al., 2015). Based on the analysis of mathematical models\nof the origins of speech forms, with a focus on their assumptions , we study\nthe fundamental question of how speech can be formed out of non--speech, at\nboth developmental and evolutionary scales. In particular, we emphasize the\nimportance of embodied self-organization , as well as the role of mechanisms of\nmotivation and active curiosity-driven exploration in speech formation. Finally\n, we discuss an evolutionary-developmental perspective of the origins of\nspeech.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 12:50:14 GMT"}], "update_date": "2016-01-06", "authors_parsed": [["Oudeyer", "Pierre-Yves", "", "Flowers"]], "citation_count": 3, "citation_status": "ok_openalex_doi", "processed_content": "open challeng in understand develop and evolut of speech form the role of embodi self organ motiv and activ explor thi articl discuss open scientif challeng for understand develop and evolut of speech form as a commentari to moulin frier et al moulin frier et al 2015 base on the analysi of mathemat model of the origin of speech form with a focu on their assumpt we studi the fundament question of how speech can be form out of non speech at both development and evolutionari scale in particular we emphas the import of embodi self organ as well as the role of mechan of motiv and activ curios driven explor in speech format final we discuss an evolutionari development perspect of the origin of speech"}
{"id": "1601.00825", "submitter": "Concetto Spampinato Dr", "authors": "Simone Palazzo, Concetto Spampinato and Daniela Giordano", "title": "Gamifying Video Object Segmentation", "comments": "Submitted to PAMI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video object segmentation can be considered as one of the most challenging\ncomputer vision problems. Indeed, so far, no existing solution is able to\neffectively deal with the peculiarities of real-world videos, especially in\ncases of articulated motion and object occlusions; limitations that appear more\nevident when we compare their performance with the human one. However, manually\nsegmenting objects in videos is largely impractical as it requires a lot of\nhuman time and concentration. To address this problem, in this paper we propose\nan interactive video object segmentation method, which exploits, on one hand,\nthe capability of humans to identify correctly objects in visual scenes, and on\nthe other hand, the collective human brainpower to solve challenging tasks. In\nparticular, our method relies on a web game to collect human inputs on object\nlocations, followed by an accurate segmentation phase achieved by optimizing an\nenergy function encoding spatial and temporal constraints between object\nregions as well as human-provided input. Performance analysis carried out on\nchallenging video datasets with some users playing the game demonstrated that\nour method shows a better trade-off between annotation times and segmentation\naccuracy than interactive video annotation and automated video object\nsegmentation approaches.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 13:48:05 GMT"}], "update_date": "2016-01-06", "authors_parsed": [["Palazzo", "Simone", ""], ["Spampinato", "Concetto", ""], ["Giordano", "Daniela", ""]], "citation_count": 14, "citation_status": "ok_openalex_title", "processed_content": "gamifi video object segment video object segment can be consid as one of the most challeng comput vision problem inde so far no exist solut is abl to effect deal with the peculiar of real world video especi in case of articul motion and object occlus limit that appear more evid when we compar their perform with the human one howev manual segment object in video is larg impract as it requir a lot of human time and concentr to address thi problem in thi paper we propos an interact video object segment method which exploit on one hand the capabl of human to identifi correctli object in visual scene and on the other hand the collect human brainpow to solv challeng task in particular our method reli on a web game to collect human input on object locat follow by an accur segment phase achiev by optim an energi function encod spatial and tempor constraint between object region as well as human provid input perform analysi carri out on challeng video dataset with some user play the game demonstr that our method show a better trade off between annot time and segment accuraci than interact video annot and autom video object segment approach"}
{"id": "1601.00833", "submitter": "Sucheta Ghosh", "authors": "Sucheta Ghosh, Milos Cernak, Sarbani Palit, B. B. Chaudhuri", "title": "An Analysis of Rhythmic Staccato-Vocalization Based on Frequency\n  Demodulation for Laughter Detection in Conversational Meetings", "comments": "5 pages, 1 figure, conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Human laugh is able to convey various kinds of meanings in human\ncommunications. There exists various kinds of human laugh signal, for example:\nvocalized laugh and non vocalized laugh. Following the theories of psychology,\namong all the vocalized laugh type, rhythmic staccato-vocalization\nsignificantly evokes the positive responses in the interactions. In this paper\nwe attempt to exploit this observation to detect human laugh occurrences, i.e.,\nthe laughter, in multiparty conversations from the AMI meeting corpus. First,\nwe separate the high energy frames from speech, leaving out the low energy\nframes through power spectral density estimation. We borrow the algorithm of\nrhythm detection from the area of music analysis to use that on the high energy\nframes. Finally, we detect rhythmic laugh frames, analyzing the candidate\nrhythmic frames using statistics. This novel approach for detection of\n`positive' rhythmic human laughter performs better than the standard laughter\nclassification baseline.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 14:13:28 GMT"}], "update_date": "2016-01-06", "authors_parsed": [["Ghosh", "Sucheta", ""], ["Cernak", "Milos", ""], ["Palit", "Sarbani", ""], ["Chaudhuri", "B. B.", ""]], "citation_count": 1, "citation_status": "ok_openalex_title", "processed_content": "an analysi of rhythmic staccato vocal base on frequenc demodul for laughter detect in convers meet human laugh is abl to convey variou kind of mean in human commun there exist variou kind of human laugh signal for exampl vocal laugh and non vocal laugh follow the theori of psycholog among all the vocal laugh type rhythmic staccato vocal significantli evok the posit respons in the interact in thi paper we attempt to exploit thi observ to detect human laugh occurr i e the laughter in multiparti convers from the ami meet corpu first we separ the high energi frame from speech leav out the low energi frame through power spectral densiti estim we borrow the algorithm of rhythm detect from the area of music analysi to use that on the high energi frame final we detect rhythmic laugh frame analyz the candid rhythmic frame use statist thi novel approach for detect of posit rhythmic human laughter perform better than the standard laughter classif baselin"}
{"id": "1601.00834", "submitter": "Jordane Lorandel M.", "authors": "Lorandel Jordane, Jean-Christophe Pr\\'evotet and Maryline H\\'elard", "title": "Fast Power and Energy Efficiency Analysis of FPGA-based Wireless\n  Base-band Processing", "comments": "Presented at HIP3ES, 2016", "journal-ref": null, "doi": null, "report-no": "HIP3ES/2016/4", "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, demands for high performance keep on increasing in the wireless\ncommunication domain. This leads to a consistent rise of the complexity and\ndesigning such systems has become a challenging task. In this context, energy\nefficiency is considered as a key topic, especially for embedded systems in\nwhich design space is often very constrained. In this paper, a fast and\naccurate power estimation approach for FPGA-based hardware systems is applied\nto a typical wireless communication system. It aims at providing power\nestimates of complete systems prior to their implementations. This is made\npossible by using a dedicated library of high-level models that are\nrepresentative of hardware IPs. Based on high-level simulations, design space\nexploration is made a lot faster and easier. The definition of a scenario and\nthe monitoring of IP's time-activities facilitate the comparison of several\ndomain-specific systems. The proposed approach and its benefits are\ndemonstrated through a typical use case in the wireless communication domain.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 14:14:21 GMT"}], "update_date": "2016-01-06", "authors_parsed": [["Jordane", "Lorandel", ""], ["Prévotet", "Jean-Christophe", ""], ["Hélard", "Maryline", ""]], "citation_count": 1, "citation_status": "ok_openalex_title", "processed_content": "fast power and energi effici analysi of fpga base wireless base band process nowaday demand for high perform keep on increas in the wireless commun domain thi lead to a consist rise of the complex and design such system ha becom a challeng task in thi context energi effici is consid as a key topic especi for embed system in which design space is often veri constrain in thi paper a fast and accur power estim approach for fpga base hardwar system is appli to a typic wireless commun system it aim at provid power estim of complet system prior to their implement thi is made possibl by use a dedic librari of high level model that are repres of hardwar ip base on high level simul design space explor is made a lot faster and easier the definit of a scenario and the monitor of ip s time activ facilit the comparison of sever domain specif system the propos approach and it benefit are demonstr through a typic use case in the wireless commun domain"}
{"id": "1601.00835", "submitter": "Mung Chiang", "authors": "Mung Chiang", "title": "Fog Networking: An Overview on Research Opportunities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The past 15 years have seen the rise of the Cloud, along with rapid increase\nin Internet backbone traffic and more sophisticated cellular core networks.\nThere are three different types of Clouds: (1) data center, (2) backbone IP\nnetwork and (3) cellular core network, responsible for computation, storage,\ncommunication and network management. Now the functions of these three types of\nClouds are descending to be among or near the end users, i.e., to the edge of\nnetworks, as Fog. This article presents an overview on research opportunities\nof Fog networking: an architecture that users one or a collaborative multitude\nof end-user clients or near-user edge devices to carry out a substantial amount\nof storage, communication and management. Architecture allocates\nfunctionalities, while engineering artifacts that may use a Fog architecture\ninclude 5G, home/personal networking, and the Internet of Things.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 14:22:23 GMT"}], "update_date": "2016-01-06", "authors_parsed": [["Chiang", "Mung", ""]], "citation_count": 49, "citation_status": "ok_openalex_title", "processed_content": "fog network an overview on research opportun the past 15 year have seen the rise of the cloud along with rapid increas in internet backbon traffic and more sophist cellular core network there are three differ type of cloud 1 data center 2 backbon ip network and 3 cellular core network respons for comput storag commun and network manag now the function of these three type of cloud are descend to be among or near the end user i e to the edg of network as fog thi articl present an overview on research opportun of fog network an architectur that user one or a collabor multitud of end user client or near user edg devic to carri out a substanti amount of storag commun and manag architectur alloc function while engin artifact that may use a fog architectur includ 5g home person network and the internet of thing"}
{"id": "1601.00839", "submitter": "Christian Wulff-Nilsen", "authors": "Christian Wulff-Nilsen", "title": "Approximate Distance Oracles for Planar Graphs with Improved Query\n  Time-Space Tradeoff", "comments": "20 pages, 9 figures of which 2 illustrate pseudo-code. This is the\n  SODA 2016 version but with the definition of C_i in Phase I fixed and the\n  analysis slightly modified accordingly. The main change is in the subsection\n  bounding query time and stretch for Phase I", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider approximate distance oracles for edge-weighted n-vertex\nundirected planar graphs. Given fixed epsilon > 0, we present a\n(1+epsilon)-approximate distance oracle with O(n(loglog n)^2) space and\nO((loglog n)^3) query time. This improves the previous best product of query\ntime and space of the oracles of Thorup (FOCS 2001, J. ACM 2004) and Klein\n(SODA 2002) from O(n log n) to O(n(loglog n)^5).\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 14:30:48 GMT"}], "update_date": "2016-01-06", "authors_parsed": [["Wulff-Nilsen", "Christian", ""]], "citation_count": 15, "citation_status": "ok_openalex_title", "processed_content": "approxim distanc oracl for planar graph with improv queri time space tradeoff we consid approxim distanc oracl for edg weight n vertex undirect planar graph given fix epsilon 0 we present a 1 epsilon approxim distanc oracl with o n loglog n 2 space and o loglog n 3 queri time thi improv the previou best product of queri time and space of the oracl of thorup foc 2001 j acm 2004 and klein soda 2002 from o n log n to o n loglog n 5"}
{"id": "1601.00846", "submitter": "Mohammad Khodaei", "authors": "Mohammad Khodaei, Hongyu Jin, and Panos Papadimitratos", "title": "Towards Deploying a Scalable & Robust Vehicular Identity and Credential\n  Management Infrastructure", "comments": "8 pages, 13 figures, IEEE Vehicular Networking Conference (VNC). IEEE\n  VNC, Dec. 2014, pp. 33-40", "journal-ref": null, "doi": "10.1109/VNC.2014.7013306", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several years of academic and industrial research efforts have converged to a\ncommon understanding on fundamental security building blocks for the upcoming\nVehicular Communication (VC) systems. There is a growing consensus towards\ndeploying a Vehicular Public-Key Infrastructure (VPKI) enables pseudonymous\nauthentication, with standardization efforts in that direction. However, there\nare still significant technical issues that remain unresolved. Existing\nproposals for instantiating the VPKI either need additional detailed\nspecifications or enhanced security and privacy features. Equally important,\nthere is limited experimental work that establishes the VPKI efficiency and\nscalability. In this paper, we are concerned with exactly these issues. We\nleverage the common VPKI approach and contribute an enhanced system with\nprecisely defined, novel features that improve its resilience and the user\nprivacy protection. In particular, we depart from the common assumption that\nthe VPKI entities are fully trusted and we improve user privacy in the face of\nan honest-but-curious security infrastructure. Moreover, we fully implement our\nVPKI, in a standard-compliant manner, and we perform an extensive evaluation.\nAlong with stronger protection and richer functionality, our system achieves\nvery significant performance improvement over prior systems - contributing the\nmost advanced VPKI towards deployment.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 14:35:24 GMT"}], "update_date": "2016-01-06", "authors_parsed": [["Khodaei", "Mohammad", ""], ["Jin", "Hongyu", ""], ["Papadimitratos", "Panos", ""]], "citation_count": 32, "citation_status": "ok_openalex_doi", "processed_content": "toward deploy a scalabl robust vehicular ident and credenti manag infrastructur sever year of academ and industri research effort have converg to a common understand on fundament secur build block for the upcom vehicular commun vc system there is a grow consensu toward deploy a vehicular public key infrastructur vpki enabl pseudonym authent with standard effort in that direct howev there are still signific technic issu that remain unresolv exist propos for instanti the vpki either need addit detail specif or enhanc secur and privaci featur equal import there is limit experiment work that establish the vpki effici and scalabl in thi paper we are concern with exactli these issu we leverag the common vpki approach and contribut an enhanc system with precis defin novel featur that improv it resili and the user privaci protect in particular we depart from the common assumpt that the vpki entiti are fulli trust and we improv user privaci in the face of an honest but curiou secur infrastructur moreov we fulli implement our vpki in a standard compliant manner and we perform an extens evalu along with stronger protect and richer function our system achiev veri signific perform improv over prior system contribut the most advanc vpki toward deploy"}
{"id": "1601.00847", "submitter": "David Breuer", "authors": "David Breuer, Zoran Nikoloski", "title": "DeFiNe: an optimisation-based method for robust disentangling of\n  filamentous networks", "comments": null, "journal-ref": "Sci Rep, 2015, 5:18267", "doi": "10.1038/srep18267", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thread-like structures are pervasive across scales, from polymeric proteins\nto root systems to galaxy filaments, and their characteristics can be readily\ninvestigated in the network formalism. Yet, network links usually represent\nonly parts of filaments, which, when neglected, may lead to erroneous\nconclusions from network-based analyses. The existing alternatives to detect\nfilaments in network representations require tuning of parameters over a large\nrange of values and treat all filaments equally, thus, precluding automated\nanalysis of diverse filamentous systems. Here, we propose a fully automated and\nrobust optimisation-based approach to detect filaments of consistent\nintensities and angles in a given network. We test and demonstrate the accuracy\nof our solution with contrived, biological, and cosmic filamentous structures.\nIn particular, we show that the proposed approach provides powerful automated\nmeans to study properties of individual actin filaments in their network\ncontext. Our solution is made publicly available as an open-source tool,\nDeFiNe, facilitating decomposition of any given network into individual\nfilaments.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2016 10:23:08 GMT"}], "update_date": "2017-06-01", "authors_parsed": [["Breuer", "David", ""], ["Nikoloski", "Zoran", ""]], "citation_count": 17, "citation_status": "ok_openalex_doi", "processed_content": "defin an optimis base method for robust disentangl of filament network thread like structur are pervas across scale from polymer protein to root system to galaxi filament and their characterist can be readili investig in the network formal yet network link usual repres onli part of filament which when neglect may lead to erron conclus from network base analys the exist altern to detect filament in network represent requir tune of paramet over a larg rang of valu and treat all filament equal thu preclud autom analysi of divers filament system here we propos a fulli autom and robust optimis base approach to detect filament of consist intens and angl in a given network we test and demonstr the accuraci of our solut with contriv biolog and cosmic filament structur in particular we show that the propos approach provid power autom mean to studi properti of individu actin filament in their network context our solut is made publicli avail as an open sourc tool defin facilit decomposit of ani given network into individu filament"}
{"id": "1601.00852", "submitter": "Ali Ghadirzadeh", "authors": "Ali Ghadirzadeh, Judith B\\\"utepage, Danica Kragic and M{\\aa}rten\n  Bj\\\"orkman", "title": "Self-learning and adaptation in a sensorimotor framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general framework to autonomously achieve a task, where autonomy\nis acquired by learning sensorimotor patterns of a robot, while it is\ninteracting with its environment. To accomplish the task, using the learned\nsensorimotor contingencies, our approach predicts a sequence of actions that\nwill lead to the desirable observations. Gaussian processes (GP) with automatic\nrelevance determination is used to learn the sensorimotor mapping. In this way,\nrelevant sensory and motor components can be systematically found in\nhigh-dimensional sensory and motor spaces. We propose an incremental GP\nlearning strategy, which discerns between situations, when an update or an\nadaptation must be implemented. RRT* is exploited to enable long-term planning\nand generating a sequence of states that lead to a given goal; while a\ngradient-based search finds the optimum action to steer to a neighbouring state\nin a single time step. Our experimental results prove the successfulness of the\nproposed framework to learn a joint space controller with high data dimensions\n(10$\\times$15). It demonstrates short training phase (less than 12 seconds),\nreal-time performance and rapid adaptations capabilities.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 15:10:08 GMT"}], "update_date": "2016-01-06", "authors_parsed": [["Ghadirzadeh", "Ali", ""], ["Bütepage", "Judith", ""], ["Kragic", "Danica", ""], ["Björkman", "Mårten", ""]], "citation_count": 7, "citation_status": "ok_openalex_title", "processed_content": "self learn and adapt in a sensorimotor framework we present a gener framework to autonom achiev a task where autonomi is acquir by learn sensorimotor pattern of a robot while it is interact with it environ to accomplish the task use the learn sensorimotor conting our approach predict a sequenc of action that will lead to the desir observ gaussian process gp with automat relev determin is use to learn the sensorimotor map in thi way relev sensori and motor compon can be systemat found in high dimension sensori and motor space we propos an increment gp learn strategi which discern between situat when an updat or an adapt must be implement rrt is exploit to enabl long term plan and gener a sequenc of state that lead to a given goal while a gradient base search find the optimum action to steer to a neighbour state in a singl time step our experiment result prove the success of the propos framework to learn a joint space control with high data dimens 10 time 15 it demonstr short train phase less than 12 second real time perform and rapid adapt capabl"}
{"id": "1601.00855", "submitter": "Pedro Saleiro", "authors": "Pedro Saleiro, Jorge Teixeira, Carlos Soares, Eug\\'enio Oliveira", "title": "TimeMachine: Entity-centric Search and Visualization of News Archives", "comments": "Advances in Information Retrieval: 38th European Conference on IR\n  Research, ECIR 2016, Padua, Italy, March 20-23, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a dynamic web tool that allows interactive search and\nvisualization of large news archives using an entity-centric approach. Users\nare able to search entities using keyword phrases expressing news stories or\nevents and the system retrieves the most relevant entities to the user query\nbased on automatically extracted and indexed entity profiles. From the\ncomputational journalism perspective, TimeMachine allows users to explore media\ncontent through time using automatic identification of entity names, jobs,\nquotations and relations between entities from co-occurrences networks\nextracted from the news articles. TimeMachine demo is available at\nhttp://maquinadotempo.sapo.pt/\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 15:18:10 GMT"}], "update_date": "2016-01-06", "authors_parsed": [["Saleiro", "Pedro", ""], ["Teixeira", "Jorge", ""], ["Soares", "Carlos", ""], ["Oliveira", "Eugénio", ""]], "citation_count": 10, "citation_status": "ok_openalex_title", "processed_content": "timemachin entiti centric search and visual of news archiv we present a dynam web tool that allow interact search and visual of larg news archiv use an entiti centric approach user are abl to search entiti use keyword phrase express news stori or event and the system retriev the most relev entiti to the user queri base on automat extract and index entiti profil from the comput journal perspect timemachin allow user to explor media content through time use automat identif of entiti name job quotat and relat between entiti from co occurr network extract from the news articl timemachin demo is avail at http maquinadotempo sapo pt"}
{"id": "1601.00863", "submitter": "Ming Yan", "authors": "Zhimin Peng, Tianyu Wu, Yangyang Xu, Ming Yan, Wotao Yin", "title": "Coordinate Friendly Structures, Algorithms and Applications", "comments": null, "journal-ref": "Annals of Mathematical Sciences and Applications, 1 (2016), 57-119", "doi": "10.4310/AMSA.2016.v1.n1.a2", "report-no": "UCLA CAM Report 16-13", "categories": "math.OC cs.CE cs.DC math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on coordinate update methods, which are useful for solving\nproblems involving large or high-dimensional datasets. They decompose a problem\ninto simple subproblems, where each updates one, or a small block of, variables\nwhile fixing others. These methods can deal with linear and nonlinear mappings,\nsmooth and nonsmooth functions, as well as convex and nonconvex problems. In\naddition, they are easy to parallelize.\n  The great performance of coordinate update methods depends on solving simple\nsub-problems. To derive simple subproblems for several new classes of\napplications, this paper systematically studies coordinate-friendly operators\nthat perform low-cost coordinate updates.\n  Based on the discovered coordinate friendly operators, as well as operator\nsplitting techniques, we obtain new coordinate update algorithms for a variety\nof problems in machine learning, image processing, as well as sub-areas of\noptimization. Several problems are treated with coordinate update for the first\ntime in history. The obtained algorithms are scalable to large instances\nthrough parallel and even asynchronous computing. We present numerical examples\nto illustrate how effective these algorithms are.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 15:33:05 GMT"}, {"version": "v2", "created": "Mon, 7 Mar 2016 23:05:07 GMT"}, {"version": "v3", "created": "Sun, 14 Aug 2016 14:29:53 GMT"}], "update_date": "2016-08-16", "authors_parsed": [["Peng", "Zhimin", ""], ["Wu", "Tianyu", ""], ["Xu", "Yangyang", ""], ["Yan", "Ming", ""], ["Yin", "Wotao", ""]], "citation_count": 60, "citation_status": "ok_openalex_doi", "processed_content": "coordin friendli structur algorithm and applic thi paper focus on coordin updat method which are use for solv problem involv larg or high dimension dataset they decompos a problem into simpl subproblem where each updat one or a small block of variabl while fix other these method can deal with linear and nonlinear map smooth and nonsmooth function as well as convex and nonconvex problem in addit they are easi to parallel the great perform of coordin updat method depend on solv simpl sub problem to deriv simpl subproblem for sever new class of applic thi paper systemat studi coordin friendli oper that perform low cost coordin updat base on the discov coordin friendli oper as well as oper split techniqu we obtain new coordin updat algorithm for a varieti of problem in machin learn imag process as well as sub area of optim sever problem are treat with coordin updat for the first time in histori the obtain algorithm are scalabl to larg instanc through parallel and even asynchron comput we present numer exampl to illustr how effect these algorithm are"}
{"id": "1601.00864", "submitter": "Yerali Gandica", "authors": "Yerali Gandica, Joao Carvalho, Fernando Sampaio Dos Aidos, Renaud\n  Lambiotte and Timoteo Carletti", "title": "On the origin of burstiness in human behavior: The wikipedia edits case", "comments": "12 pages, 7 figures and 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of human activities exhibit a bursty pattern, namely periods of very\nhigh activity that are followed by rest periods. Records of this process\ngenerate time series of events whose inter-event times follow a probability\ndistribution that displays a fat tail. The grounds for such phenomenon are not\nyet clearly understood. In the present work we use the freely available\nWikipedia's editing records to tackle this question by measuring the level of\nburstiness, as well as the memory effect of the editing tasks performed by\ndifferent editors in different pages. Our main finding is that, even though the\nediting activity is conditioned by the circadian 24 hour cycle, the conditional\nprobability of an activity of a given duration at a given time of the day is\nindependent from the latter. This suggests that the human activity seems to be\nrelated to the high \"cost\" of starting an action as opposed to the much lower\n\"cost\" of continuing that action.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 15:35:03 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2016 07:22:54 GMT"}], "update_date": "2016-01-11", "authors_parsed": [["Gandica", "Yerali", ""], ["Carvalho", "Joao", ""], ["Aidos", "Fernando Sampaio Dos", ""], ["Lambiotte", "Renaud", ""], ["Carletti", "Timoteo", ""]], "citation_count": 7, "citation_status": "ok_openalex_title", "processed_content": "on the origin of bursti in human behavior the wikipedia edit case a number of human activ exhibit a bursti pattern name period of veri high activ that are follow by rest period record of thi process gener time seri of event whose inter event time follow a probabl distribut that display a fat tail the ground for such phenomenon are not yet clearli understood in the present work we use the freeli avail wikipedia s edit record to tackl thi question by measur the level of bursti as well as the memori effect of the edit task perform by differ editor in differ page our main find is that even though the edit activ is condit by the circadian 24 hour cycl the condit probabl of an activ of a given durat at a given time of the day is independ from the latter thi suggest that the human activ seem to be relat to the high cost of start an action as oppos to the much lower cost of continu that action"}
{"id": "1601.00873", "submitter": "Vineeth Varma S", "authors": "Mariem Mhiri, Vineeth S. Varma, Karim Cheikhrouhou, Samson Lasaulce\n  and Abdelaziz Samet", "title": "Cross-layer distributed power control: A repeated games formulation to\n  improve the sum energy-efficiency", "comments": "36 pages, single column draft format", "journal-ref": "EURASIP Journal on Wireless Communications and Networking 2015, 1\n  (2015): 1-16", "doi": "10.1186/s13638-015-0486-z", "report-no": null, "categories": "cs.NI cs.GT cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main objective of this work is to improve the energy-efficiency (EE) of a\nmultiple access channel (MAC) system, through power control, in a distributed\nmanner. In contrast with many existing works on energy-efficient power control,\nwhich ignore the possible presence of a queue at the transmitter, we consider a\nnew generalized cross-layer EE metric. This approach is relevant when the\ntransmitters have a non-zero energy cost even when the radiated power is zero\nand takes into account the presence of a finite packet buffer and packet\narrival at the transmitter. As the Nash equilibrium (NE) is an\nenergy-inefficient solution, the present work aims at overcoming this deficit\nby improving the global energy-efficiency. Indeed, as the considered system has\nmultiple agencies each with their own interest, the performance metric\nreflecting the individual interest of each decision maker is the global\nenergy-efficiency defined then as the sum over individual energy-efficiencies.\nRepeated games (RG) are investigated through the study of two dynamic games\n(finite RG and discounted RG), whose equilibrium is defined when introducing a\nnew operating point (OP), Pareto-dominating the NE and relying only on\nindividual channel state information (CSI). Accordingly, closed-form\nexpressions of the minimum number of stages of the game for finite RG (FRG) and\nthe maximum discount factor of the discounted RG (DRG) were established. The\ncross-layer model in the RG formulation leads to achieving a shorter minimum\nnumber of stages in the FRG even for higher number of users. In addition, the\nsocial welfare (sum of utilities) in the DRG decreases slightly with the\ncross-layer model when the number of users increases while it is reduced\nconsiderably with the Goodman model. Finally, we show that in real systems with\nrandom packet arrivals, the cross-layer power control algorithm outperforms the\nGoodman algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 15:49:13 GMT"}], "update_date": "2016-01-06", "authors_parsed": [["Mhiri", "Mariem", ""], ["Varma", "Vineeth S.", ""], ["Cheikhrouhou", "Karim", ""], ["Lasaulce", "Samson", ""], ["Samet", "Abdelaziz", ""]], "citation_count": 2, "citation_status": "ok_openalex_doi", "processed_content": "cross layer distribut power control a repeat game formul to improv the sum energi effici the main object of thi work is to improv the energi effici ee of a multipl access channel mac system through power control in a distribut manner in contrast with mani exist work on energi effici power control which ignor the possibl presenc of a queue at the transmitt we consid a new gener cross layer ee metric thi approach is relev when the transmitt have a non zero energi cost even when the radiat power is zero and take into account the presenc of a finit packet buffer and packet arriv at the transmitt as the nash equilibrium ne is an energi ineffici solut the present work aim at overcom thi deficit by improv the global energi effici inde as the consid system ha multipl agenc each with their own interest the perform metric reflect the individu interest of each decis maker is the global energi effici defin then as the sum over individu energi effici repeat game rg are investig through the studi of two dynam game finit rg and discount rg whose equilibrium is defin when introduc a new oper point op pareto domin the ne and reli onli on individu channel state inform csi accordingli close form express of the minimum number of stage of the game for finit rg frg and the maximum discount factor of the discount rg drg were establish the cross layer model in the rg formul lead to achiev a shorter minimum number of stage in the frg even for higher number of user in addit the social welfar sum of util in the drg decreas slightli with the cross layer model when the number of user increas while it is reduc consider with the goodman model final we show that in real system with random packet arriv the cross layer power control algorithm outperform the goodman algorithm"}
{"id": "1601.00876", "submitter": "Isaac Mabillard", "authors": "Isaac Mabillard and Uli Wagner", "title": "Eliminating Higher-Multiplicity Intersections, II. The Deleted Product\n  Criterion in the $r$-Metastable Range", "comments": "35 pages, 10 figures (v2: reference for the algorithmic aspects\n  updated & appendix on Block Bundles added)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GT cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by Tverberg-type problems in topological combinatorics and by\nclassical results about embeddings (maps without double points), we study the\nquestion whether a finite simplicial complex K can be mapped into R^d without\nhigher-multiplicity intersections. We focus on conditions for the existence of\nalmost r-embeddings, i.e., maps from K to R^d without r-intersection points\namong any set of r pairwise disjoint simplices of K.\n  Generalizing the classical Haefliger-Weber embeddability criterion, we show\nthat a well-known necessary deleted product condition for the existence of\nalmost r-embeddings is sufficient in a suitable r-metastable range of\ndimensions (r d > (r+1) dim K +2). This significantly extends one of the main\nresults of our previous paper (which treated the special case where d=rk and\ndim K=(r-1)k, for some k> 3).\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 15:56:53 GMT"}, {"version": "v2", "created": "Tue, 18 Oct 2016 19:58:38 GMT"}], "update_date": "2016-10-19", "authors_parsed": [["Mabillard", "Isaac", ""], ["Wagner", "Uli", ""]], "citation_count": -1, "citation_status": "openalex_title_http_403", "processed_content": "elimin higher multipl intersect ii the delet product criterion in the r metast rang motiv by tverberg type problem in topolog combinator and by classic result about embed map without doubl point we studi the question whether a finit simplici complex k can be map into r d without higher multipl intersect we focu on condit for the exist of almost r embed i e map from k to r d without r intersect point among ani set of r pairwis disjoint simplic of k gener the classic haeflig weber embedd criterion we show that a well known necessari delet product condit for the exist of almost r embed is suffici in a suitabl r metast rang of dimens r d r 1 dim k 2 thi significantli extend one of the main result of our previou paper which treat the special case where d rk and dim k r 1 k for some k 3"}
{"id": "1601.00877", "submitter": "Ulrik Schultz", "authors": "Christian Schlegel, Ulrik Pagh Schultz, Serge Stinckwich, Sebastian\n  Wrede", "title": "Proceedings of the Sixth International Workshop on Domain-Specific\n  Languages and Models for Robotic Systems (DSLRob 2015)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Sixth International Workshop on Domain-Specific Languages and Models for\nRobotic Systems (DSLRob'15) was held September 28, 2015 in Hamburg (Germany),\nas part of the IROS 2015 conference. The main topics of the workshop were\nDomain-Specific Languages (DSLs) and Model-driven Software Development (MDSD)\nfor robotics. A domain-specific language is a programming language dedicated to\na particular problem domain that offers specific notations and abstractions\nthat increase programmer productivity within that domain. Model-driven software\ndevelopment offers a high-level way for domain users to specify the\nfunctionality of their system at the right level of abstraction. DSLs and\nmodels have historically been used for programming complex systems. However\nrecently they have garnered interest as a separate field of study. Robotic\nsystems blend hardware and software in a holistic way that intrinsically raises\nmany crosscutting concerns (concurrency, uncertainty, time constraints, ...),\nfor which reason, traditional general-purpose languages often lead to a poor\nfit between the language features and the implementation requirements. DSLs and\nmodels offer a powerful, systematic way to overcome this problem, enabling the\nprogrammer to quickly and precisely implement novel software solutions to\ncomplex problems within the robotics domain.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 15:57:27 GMT"}, {"version": "v2", "created": "Wed, 20 Jan 2016 19:19:23 GMT"}], "update_date": "2016-01-21", "authors_parsed": [["Schlegel", "Christian", ""], ["Schultz", "Ulrik Pagh", ""], ["Stinckwich", "Serge", ""], ["Wrede", "Sebastian", ""]], "citation_count": -1, "citation_status": "openalex_title_http_429", "processed_content": "proceed of the sixth intern workshop on domain specif languag and model for robot system dslrob 2015 the sixth intern workshop on domain specif languag and model for robot system dslrob 15 wa held septemb 28 2015 in hamburg germani as part of the iro 2015 confer the main topic of the workshop were domain specif languag dsl and model driven softwar develop mdsd for robot a domain specif languag is a program languag dedic to a particular problem domain that offer specif notat and abstract that increas programm product within that domain model driven softwar develop offer a high level way for domain user to specifi the function of their system at the right level of abstract dsl and model have histor been use for program complex system howev recent they have garner interest as a separ field of studi robot system blend hardwar and softwar in a holist way that intrins rais mani crosscut concern concurr uncertainti time constraint for which reason tradit gener purpos languag often lead to a poor fit between the languag featur and the implement requir dsl and model offer a power systemat way to overcom thi problem enabl the programm to quickli and precis implement novel softwar solut to complex problem within the robot domain"}
{"id": "1601.00881", "submitter": "Tomoyuki Obuchi", "authors": "Tomoyuki Obuchi and Yoshiyuki Kabashima", "title": "Cross validation in LASSO and its acceleration", "comments": "32 pages, 7 figures", "journal-ref": null, "doi": "10.1088/1742-5468/2016/05/053304", "report-no": null, "categories": "cs.IT cond-mat.dis-nn cond-mat.stat-mech math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate leave-one-out cross validation (CV) as a determinator of the\nweight of the penalty term in the least absolute shrinkage and selection\noperator (LASSO). First, on the basis of the message passing algorithm and a\nperturbative discussion assuming that the number of observations is\nsufficiently large, we provide simple formulas for approximately assessing two\ntypes of CV errors, which enable us to significantly reduce the necessary cost\nof computation. These formulas also provide a simple connection of the CV\nerrors to the residual sums of squares between the reconstructed and the given\nmeasurements. Second, on the basis of this finding, we analytically evaluate\nthe CV errors when the design matrix is given as a simple random matrix in the\nlarge size limit by using the replica method. Finally, these results are\ncompared with those of numerical simulations on finite-size systems and are\nconfirmed to be correct. We also apply the simple formulas of the first type of\nCV error to an actual dataset of the supernovae.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2015 02:50:51 GMT"}, {"version": "v2", "created": "Fri, 4 Mar 2016 09:34:44 GMT"}], "update_date": "2016-06-22", "authors_parsed": [["Obuchi", "Tomoyuki", ""], ["Kabashima", "Yoshiyuki", ""]], "citation_count": 67, "citation_status": "ok_openalex_doi", "processed_content": "cross valid in lasso and it acceler we investig leav one out cross valid cv as a determin of the weight of the penalti term in the least absolut shrinkag and select oper lasso first on the basi of the messag pass algorithm and a perturb discuss assum that the number of observ is suffici larg we provid simpl formula for approxim assess two type of cv error which enabl us to significantli reduc the necessari cost of comput these formula also provid a simpl connect of the cv error to the residu sum of squar between the reconstruct and the given measur second on the basi of thi find we analyt evalu the cv error when the design matrix is given as a simpl random matrix in the larg size limit by use the replica method final these result are compar with those of numer simul on finit size system and are confirm to be correct we also appli the simpl formula of the first type of cv error to an actual dataset of the supernova"}
{"id": "1601.00883", "submitter": "Bing Yao", "authors": "Bing Yao, Ming Yao, Xiang-en Chen", "title": "Probing Graph Proper Total Colorings With Additional Constrained\n  Conditions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph colorings are becoming an increasingly useful family of mathematical\nmodels for a broad range of applications, such as time tabling and scheduling,\nfrequency assignment, register allocation, computer security and so on. Graph\nproper total colorings with additional constrained conditions have been\ninvestigated intensively in the last decade year. In this article some new\ngraph proper total colorings with additional constrained conditions are\ndefined, and approximations to the chromatic numbers of these colorings are\nresearched, as well as some graphs having these colorings have been verified.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2015 03:12:56 GMT"}], "update_date": "2016-01-06", "authors_parsed": [["Yao", "Bing", ""], ["Yao", "Ming", ""], ["Chen", "Xiang-en", ""]], "citation_count": 0, "citation_status": "ok_openalex_title", "processed_content": "probe graph proper total color with addit constrain condit graph color are becom an increasingli use famili of mathemat model for a broad rang of applic such as time tabl and schedul frequenc assign regist alloc comput secur and so on graph proper total color with addit constrain condit have been investig intens in the last decad year in thi articl some new graph proper total color with addit constrain condit are defin and approxim to the chromat number of these color are research as well as some graph have these color have been verifi"}
{"id": "1601.00893", "submitter": "Oren Melamud", "authors": "Oren Melamud, David McClosky, Siddharth Patwardhan, Mohit Bansal", "title": "The Role of Context Types and Dimensionality in Learning Word Embeddings", "comments": "Accepted to NAACL 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide the first extensive evaluation of how using different types of\ncontext to learn skip-gram word embeddings affects performance on a wide range\nof intrinsic and extrinsic NLP tasks. Our results suggest that while intrinsic\ntasks tend to exhibit a clear preference to particular types of contexts and\nhigher dimensionality, more careful tuning is required for finding the optimal\nsettings for most of the extrinsic tasks that we considered. Furthermore, for\nthese extrinsic tasks, we find that once the benefit from increasing the\nembedding dimensionality is mostly exhausted, simple concatenation of word\nembeddings, learned with different context types, can yield further performance\ngains. As an additional contribution, we propose a new variant of the skip-gram\nmodel that learns word embeddings from weighted contexts of substitute words.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 16:28:42 GMT"}, {"version": "v2", "created": "Wed, 19 Jul 2017 15:32:54 GMT"}], "update_date": "2017-07-20", "authors_parsed": [["Melamud", "Oren", ""], ["McClosky", "David", ""], ["Patwardhan", "Siddharth", ""], ["Bansal", "Mohit", ""]], "citation_count": 105, "citation_status": "ok_openalex_title", "processed_content": "the role of context type and dimension in learn word embed we provid the first extens evalu of how use differ type of context to learn skip gram word embed affect perform on a wide rang of intrins and extrins nlp task our result suggest that while intrins task tend to exhibit a clear prefer to particular type of context and higher dimension more care tune is requir for find the optim set for most of the extrins task that we consid furthermor for these extrins task we find that onc the benefit from increas the embed dimension is mostli exhaust simpl concaten of word embed learn with differ context type can yield further perform gain as an addit contribut we propos a new variant of the skip gram model that learn word embed from weight context of substitut word"}
{"id": "1601.00894", "submitter": "Daniel Bates", "authors": "Daniel Bates, Alex Chadwick and Robert Mullins", "title": "Configurable memory systems for embedded many-core processors", "comments": "Presented at HIP3ES, 2016", "journal-ref": null, "doi": null, "report-no": "HIP3ES/2016/2", "categories": "cs.AR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The memory system of a modern embedded processor consumes a large fraction of\ntotal system energy. We explore a range of different configuration options and\nshow that a reconfigurable design can make better use of the resources\navailable to it than any fixed implementation, and provide large improvements\nin both performance and energy consumption. Reconfigurability becomes\nincreasingly useful as resources become more constrained, so is particularly\nrelevant in the embedded space.\n  For an optimised architectural configuration, we show that a configurable\ncache system performs an average of 20% (maximum 70%) better than the best\nfixed implementation when two programs are competing for the same resources,\nand reduces cache miss rate by an average of 70% (maximum 90%). We then present\na case study of AES encryption and decryption, and find that a custom memory\nconfiguration can almost double performance, with further benefits being\nachieved by specialising the task of each core when parallelising the program.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 16:29:17 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2016 12:12:42 GMT"}], "update_date": "2016-01-08", "authors_parsed": [["Bates", "Daniel", ""], ["Chadwick", "Alex", ""], ["Mullins", "Robert", ""]], "citation_count": 1, "citation_status": "ok_openalex_title", "processed_content": "configur memori system for embed mani core processor the memori system of a modern embed processor consum a larg fraction of total system energi we explor a rang of differ configur option and show that a reconfigur design can make better use of the resourc avail to it than ani fix implement and provid larg improv in both perform and energi consumpt reconfigur becom increasingli use as resourc becom more constrain so is particularli relev in the embed space for an optimis architectur configur we show that a configur cach system perform an averag of 20 maximum 70 better than the best fix implement when two program are compet for the same resourc and reduc cach miss rate by an averag of 70 maximum 90 we then present a case studi of ae encrypt and decrypt and find that a custom memori configur can almost doubl perform with further benefit be achiev by specialis the task of each core when parallelis the program"}
{"id": "1601.00899", "submitter": "Jingbo Liu", "authors": "Jingbo Liu and Paul Cuff and Sergio Verd\\'u", "title": "Secret Key Generation with Limited Interaction", "comments": "50 pages; short version appeared in ISIT 2016. Removed an incorrect\n  result in the previous arXiv version (see acknowledgement)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A basic two-terminal secret key generation model is considered, where the\ninteractive communication rate between the terminals may be limited, and in\nparticular may not be enough to achieve the maximum key rate. We first prove a\nmulti-letter characterization of the key-communication rate region (where the\nnumber of auxiliary random variables depend on the number of rounds of the\ncommunication), and then provide an equivalent but simpler characterization in\nterms of concave envelopes in the case of unlimited number of rounds. Two\nextreme cases are given special attention. First, in the regime of very low\ncommunication rates, the \\emph{key bits per interaction bit} (KBIB) is\nexpressed with a new \"symmetric strong data processing constant\", which has a\nconcave envelope characterization analogous to that of the conventional strong\ndata processing constant. The symmetric strong data processing constant can be\nupper bounded by the supremum of the maximal correlation coefficient over a set\nof distributions, which allows us to determine the KBIB for binary symmetric\nsources, and conclude, in particular, that the interactive scheme is not more\nefficient than the one-way scheme at least in the low communication-rate\nregime. Second, a new characterization of the \\emph{minimum interaction rate\nneeded for achieving the maximum key rate} (MIMK) is given, and we resolve a\nconjecture by Tyagi regarding the MIMK for (possibly nonsymmetric) binary\nsources. We also propose a new conjecture for binary symmetric sources that the\ninteractive scheme is not more efficient than the one-way scheme at any\ncommunication rate.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 16:44:01 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2016 01:41:02 GMT"}, {"version": "v3", "created": "Tue, 28 Mar 2017 02:31:47 GMT"}], "update_date": "2017-03-29", "authors_parsed": [["Liu", "Jingbo", ""], ["Cuff", "Paul", ""], ["Verdú", "Sergio", ""]], "citation_count": 39, "citation_status": "ok_openalex_title", "processed_content": "secret key gener with limit interact a basic two termin secret key gener model is consid where the interact commun rate between the termin may be limit and in particular may not be enough to achiev the maximum key rate we first prove a multi letter character of the key commun rate region where the number of auxiliari random variabl depend on the number of round of the commun and then provid an equival but simpler character in term of concav envelop in the case of unlimit number of round two extrem case are given special attent first in the regim of veri low commun rate the emph key bit per interact bit kbib is express with a new symmetr strong data process constant which ha a concav envelop character analog to that of the convent strong data process constant the symmetr strong data process constant can be upper bound by the supremum of the maxim correl coeffici over a set of distribut which allow us to determin the kbib for binari symmetr sourc and conclud in particular that the interact scheme is not more effici than the one way scheme at least in the low commun rate regim second a new character of the emph minimum interact rate need for achiev the maximum key rate mimk is given and we resolv a conjectur by tyagi regard the mimk for possibl nonsymmetr binari sourc we also propos a new conjectur for binari symmetr sourc that the interact scheme is not more effici than the one way scheme at ani commun rate"}
{"id": "1601.00900", "submitter": "Lachlan Gunn", "authors": "Lachlan J. Gunn, Fran\\c{c}ois Chapeau-Blondeau, Mark McDonnell, Bruce\n  Davis, Andrew Allison, and Derek Abbott", "title": "Too good to be true: when overwhelming evidence fails to convince", "comments": null, "journal-ref": null, "doi": "10.1098/rspa.2015.0748", "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Is it possible for a large sequence of measurements or observations, which\nsupport a hypothesis, to counterintuitively decrease our confidence? Can\nunanimous support be too good to be true? The assumption of independence is\noften made in good faith, however rarely is consideration given to whether a\nsystemic failure has occurred.\n  Taking this into account can cause certainty in a hypothesis to decrease as\nthe evidence for it becomes apparently stronger. We perform a probabilistic\nBayesian analysis of this effect with examples based on (i) archaeological\nevidence, (ii) weighing of legal evidence, and (iii) cryptographic primality\ntesting.\n  We find that even with surprisingly low systemic failure rates high\nconfidence is very difficult to achieve and in particular we find that certain\nanalyses of cryptographically-important numerical tests are highly optimistic,\nunderestimating their false-negative rate by as much as a factor of $2^{80}$.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 16:44:38 GMT"}], "update_date": "2016-04-27", "authors_parsed": [["Gunn", "Lachlan J.", ""], ["Chapeau-Blondeau", "François", ""], ["McDonnell", "Mark", ""], ["Davis", "Bruce", ""], ["Allison", "Andrew", ""], ["Abbott", "Derek", ""]], "citation_count": 32, "citation_status": "ok_openalex_doi", "processed_content": "too good to be true when overwhelm evid fail to convinc is it possibl for a larg sequenc of measur or observ which support a hypothesi to counterintuit decreas our confid can unanim support be too good to be true the assumpt of independ is often made in good faith howev rare is consider given to whether a system failur ha occur take thi into account can caus certainti in a hypothesi to decreas as the evid for it becom appar stronger we perform a probabilist bayesian analysi of thi effect with exampl base on i archaeolog evid ii weigh of legal evid and iii cryptograph primal test we find that even with surprisingli low system failur rate high confid is veri difficult to achiev and in particular we find that certain analys of cryptograph import numer test are highli optimist underestim their fals neg rate by as much as a factor of 2 80"}
{"id": "1601.00901", "submitter": "Janez Starc", "authors": "Janez Starc and Dunja Mladeni\\'c", "title": "Joint learning of ontology and semantic parser from text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic parsing methods are used for capturing and representing semantic\nmeaning of text. Meaning representation capturing all the concepts in the text\nmay not always be available or may not be sufficiently complete. Ontologies\nprovide a structured and reasoning-capable way to model the content of a\ncollection of texts. In this work, we present a novel approach to joint\nlearning of ontology and semantic parser from text. The method is based on\nsemi-automatic induction of a context-free grammar from semantically annotated\ntext. The grammar parses the text into semantic trees. Both, the grammar and\nthe semantic trees are used to learn the ontology on several levels -- classes,\ninstances, taxonomic and non-taxonomic relations. The approach was evaluated on\nthe first sentences of Wikipedia pages describing people.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 16:56:28 GMT"}], "update_date": "2016-01-06", "authors_parsed": [["Starc", "Janez", ""], ["Mladenić", "Dunja", ""]], "citation_count": 5, "citation_status": "ok_openalex_title", "processed_content": "joint learn of ontolog and semant parser from text semant pars method are use for captur and repres semant mean of text mean represent captur all the concept in the text may not alway be avail or may not be suffici complet ontolog provid a structur and reason capabl way to model the content of a collect of text in thi work we present a novel approach to joint learn of ontolog and semant parser from text the method is base on semi automat induct of a context free grammar from semant annot text the grammar pars the text into semant tree both the grammar and the semant tree are use to learn the ontolog on sever level class instanc taxonom and non taxonom relat the approach wa evalu on the first sentenc of wikipedia page describ peopl"}
{"id": "1601.00909", "submitter": "Mihai Alexandru Petrovici", "authors": "Mihai A. Petrovici, Ilja Bytschok, Johannes Bill, Johannes Schemmel\n  and Karlheinz Meier", "title": "The high-conductance state enables neural sampling in networks of LIF\n  neurons", "comments": "3 pages, 1 figure", "journal-ref": null, "doi": "10.1186/1471-2202-16-S1-O2", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn cs.NE physics.bio-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The apparent stochasticity of in-vivo neural circuits has long been\nhypothesized to represent a signature of ongoing stochastic inference in the\nbrain. More recently, a theoretical framework for neural sampling has been\nproposed, which explains how sample-based inference can be performed by\nnetworks of spiking neurons. One particular requirement of this approach is\nthat the neural response function closely follows a logistic curve.\n  Analytical approaches to calculating neural response functions have been the\nsubject of many theoretical studies. In order to make the problem tractable,\nparticular assumptions regarding the neural or synaptic parameters are usually\nmade. However, biologically significant activity regimes exist which are not\ncovered by these approaches: Under strong synaptic bombardment, as is often the\ncase in cortex, the neuron is shifted into a high-conductance state (HCS)\ncharacterized by a small membrane time constant. In this regime, synaptic time\nconstants and refractory periods dominate membrane dynamics.\n  The core idea of our approach is to separately consider two different \"modes\"\nof spiking dynamics: burst spiking and transient quiescence, in which the\nneuron does not spike for longer periods. We treat the former by propagating\nthe PDF of the effective membrane potential from spike to spike within a burst,\nwhile using a diffusion approximation for the latter. We find that our\nprediction of the neural response function closely matches simulation data.\nMoreover, in the HCS scenario, we show that the neural response function\nbecomes symmetric and can be well approximated by a logistic function, thereby\nproviding the correct dynamics in order to perform neural sampling. We hereby\nprovide not only a normative framework for Bayesian inference in cortex, but\nalso powerful applications of low-power, accelerated neuromorphic systems to\nrelevant machine learning tasks.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 17:15:37 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Petrovici", "Mihai A.", ""], ["Bytschok", "Ilja", ""], ["Bill", "Johannes", ""], ["Schemmel", "Johannes", ""], ["Meier", "Karlheinz", ""]], "citation_count": 16, "citation_status": "ok_openalex_doi", "processed_content": "the high conduct state enabl neural sampl in network of lif neuron the appar stochast of in vivo neural circuit ha long been hypothes to repres a signatur of ongo stochast infer in the brain more recent a theoret framework for neural sampl ha been propos which explain how sampl base infer can be perform by network of spike neuron one particular requir of thi approach is that the neural respons function close follow a logist curv analyt approach to calcul neural respons function have been the subject of mani theoret studi in order to make the problem tractabl particular assumpt regard the neural or synapt paramet are usual made howev biolog signific activ regim exist which are not cover by these approach under strong synapt bombard as is often the case in cortex the neuron is shift into a high conduct state hc character by a small membran time constant in thi regim synapt time constant and refractori period domin membran dynam the core idea of our approach is to separ consid two differ mode of spike dynam burst spike and transient quiescenc in which the neuron doe not spike for longer period we treat the former by propag the pdf of the effect membran potenti from spike to spike within a burst while use a diffus approxim for the latter we find that our predict of the neural respons function close match simul data moreov in the hc scenario we show that the neural respons function becom symmetr and can be well approxim by a logist function therebi provid the correct dynam in order to perform neural sampl we herebi provid not onli a norm framework for bayesian infer in cortex but also power applic of low power acceler neuromorph system to relev machin learn task"}
{"id": "1601.00912", "submitter": "Alexander Kott", "authors": "Alexander Kott, Nikolai Stoianov, Nazife Baykal, Alfred Moller,\n  Reginald Sawilla, Pram Jain, Mona Lange, and Cristian Vidu", "title": "Assessing Mission Impact of Cyberattacks: Report of the NATO IST-128\n  Workshop", "comments": null, "journal-ref": null, "doi": null, "report-no": "ARL-TR-7566", "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report presents the results of a workshop conducted by the North\nAtlantic Treaty Organization (NATO) Information Systems Technology (IST) Panel\nin Istanbul, Turkey, in June 2015 to explore science and technology for\ncharacterizing the impact of cyber-attacks on missions. Military mission\nsuccess is highly dependent on the communications and information systems\n(CISs) that support the mission and their use in the cyber battlespace. The\ninexorably growing dependency on computational information processing for\nweapons, intelligence, communication, and logistics systems continues to\nincrease the vulnerability of missions to various cyber threats. Attacks on\nCISs or other cyber incidents degrade or disrupt the usage of CISs, and the\nresulting mission capability, performance, and completion. These incidents are\nexpected to increase in frequency and sophistication. The workshop participants\nconcluded that the key to solving the mission impact assessment problem was in\nadopting and developing a new model-driven paradigm that creates and validates\nmechanisms of modeling the mission organization, the mission(s), and the\ncyber-vulnerable systems that support the mission(s). Such models then simulate\nor portray the impacts of the cyber-attacks. In addition, such model-based\nanalysis could explore multiple alternative mitigation and work-around\nstrategies - an essential part of coping with mission impact - and select the\noptimal course of mitigating actions. Only such a paradigm can be expected to\nprovide meaningful, actionable information about mission impacts that have not\nbeen seen before or do not match prior experiences and patterns. The papers\npresented at this workshop are available in an accompanying volume, Proceedings\nof the NATO Workshop IST-128, Assessing Mission Impact of Cyber Attacks.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 17:29:45 GMT"}], "update_date": "2016-01-06", "authors_parsed": [["Kott", "Alexander", ""], ["Stoianov", "Nikolai", ""], ["Baykal", "Nazife", ""], ["Moller", "Alfred", ""], ["Sawilla", "Reginald", ""], ["Jain", "Pram", ""], ["Lange", "Mona", ""], ["Vidu", "Cristian", ""]], "citation_count": 5, "citation_status": "ok_openalex_title", "processed_content": "assess mission impact of cyberattack report of the nato ist 128 workshop thi report present the result of a workshop conduct by the north atlant treati organ nato inform system technolog ist panel in istanbul turkey in june 2015 to explor scienc and technolog for character the impact of cyber attack on mission militari mission success is highli depend on the commun and inform system ciss that support the mission and their use in the cyber battlespac the inexor grow depend on comput inform process for weapon intellig commun and logist system continu to increas the vulner of mission to variou cyber threat attack on ciss or other cyber incid degrad or disrupt the usag of ciss and the result mission capabl perform and complet these incid are expect to increas in frequenc and sophist the workshop particip conclud that the key to solv the mission impact assess problem wa in adopt and develop a new model driven paradigm that creat and valid mechan of model the mission organ the mission s and the cyber vulner system that support the mission s such model then simul or portray the impact of the cyber attack in addit such model base analysi could explor multipl altern mitig and work around strategi an essenti part of cope with mission impact and select the optim cours of mitig action onli such a paradigm can be expect to provid meaning action inform about mission impact that have not been seen befor or do not match prior experi and pattern the paper present at thi workshop are avail in an accompani volum proceed of the nato workshop ist 128 assess mission impact of cyber attack"}
{"id": "1601.00917", "submitter": "Jie Fu", "authors": "Jie Fu, Hongyin Luo, Jiashi Feng, Kian Hsiang Low, Tat-Seng Chua", "title": "DrMAD: Distilling Reverse-Mode Automatic Differentiation for Optimizing\n  Hyperparameters of Deep Neural Networks", "comments": "International Joint Conference on Artificial Intelligence, IJCAI,\n  2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of deep neural networks is well-known to be sensitive to the\nsetting of their hyperparameters. Recent advances in reverse-mode automatic\ndifferentiation allow for optimizing hyperparameters with gradients. The\nstandard way of computing these gradients involves a forward and backward pass\nof computations. However, the backward pass usually needs to consume\nunaffordable memory to store all the intermediate variables to exactly reverse\nthe forward training procedure. In this work we propose a simple but effective\nmethod, DrMAD, to distill the knowledge of the forward pass into a shortcut\npath, through which we approximately reverse the training trajectory.\nExperiments on several image benchmark datasets show that DrMAD is at least 45\ntimes faster and consumes 100 times less memory compared to state-of-the-art\nmethods for optimizing hyperparameters with minimal compromise to its\neffectiveness. To the best of our knowledge, DrMAD is the first research\nattempt to make it practical to automatically tune thousands of hyperparameters\nof deep neural networks. The code can be downloaded from\nhttps://github.com/bigaidream-projects/drmad\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 17:43:15 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2016 05:57:51 GMT"}, {"version": "v3", "created": "Tue, 26 Jan 2016 11:43:31 GMT"}, {"version": "v4", "created": "Fri, 5 Feb 2016 05:45:35 GMT"}, {"version": "v5", "created": "Wed, 6 Apr 2016 15:55:19 GMT"}], "update_date": "2016-04-07", "authors_parsed": [["Fu", "Jie", ""], ["Luo", "Hongyin", ""], ["Feng", "Jiashi", ""], ["Low", "Kian Hsiang", ""], ["Chua", "Tat-Seng", ""]], "citation_count": 11, "citation_status": "ok_openalex_title", "processed_content": "drmad distil revers mode automat differenti for optim hyperparamet of deep neural network the perform of deep neural network is well known to be sensit to the set of their hyperparamet recent advanc in revers mode automat differenti allow for optim hyperparamet with gradient the standard way of comput these gradient involv a forward and backward pass of comput howev the backward pass usual need to consum unafford memori to store all the intermedi variabl to exactli revers the forward train procedur in thi work we propos a simpl but effect method drmad to distil the knowledg of the forward pass into a shortcut path through which we approxim revers the train trajectori experi on sever imag benchmark dataset show that drmad is at least 45 time faster and consum 100 time less memori compar to state of the art method for optim hyperparamet with minim compromis to it effect to the best of our knowledg drmad is the first research attempt to make it practic to automat tune thousand of hyperparamet of deep neural network the code can be download from http github com bigaidream project drmad"}
{"id": "1601.00925", "submitter": "Tim Vor Der Br\\\"uck", "authors": "Tim vor der Br\\\"uck, Steffen Eger, Alexander Mehler", "title": "Complex Decomposition of the Negative Distance kernel", "comments": "Proceedings of the IEEE International Conference on Machine Learning\n  an Applications, Miami, Florida, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Support Vector Machine (SVM) has become a very popular machine learning\nmethod for text classification. One reason for this relates to the range of\nexisting kernels which allow for classifying data that is not linearly\nseparable. The linear, polynomial and RBF (Gaussian Radial Basis Function)\nkernel are commonly used and serve as a basis of comparison in our study. We\nshow how to derive the primal form of the quadratic Power Kernel (PK) -- also\ncalled the Negative Euclidean Distance Kernel (NDK) -- by means of complex\nnumbers. We exemplify the NDK in the framework of text categorization using the\nDewey Document Classification (DDC) as the target scheme. Our evaluation shows\nthat the power kernel produces F-scores that are comparable to the reference\nkernels, but is -- except for the linear kernel -- faster to compute. Finally,\nwe show how to extend the NDK-approach by including the Mahalanobis distance.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 18:16:07 GMT"}], "update_date": "2016-01-06", "authors_parsed": [["der Brück", "Tim vor", ""], ["Eger", "Steffen", ""], ["Mehler", "Alexander", ""]], "citation_count": 3, "citation_status": "ok_openalex_title", "processed_content": "complex decomposit of the neg distanc kernel a support vector machin svm ha becom a veri popular machin learn method for text classif one reason for thi relat to the rang of exist kernel which allow for classifi data that is not linearli separ the linear polynomi and rbf gaussian radial basi function kernel are commonli use and serv as a basi of comparison in our studi we show how to deriv the primal form of the quadrat power kernel pk also call the neg euclidean distanc kernel ndk by mean of complex number we exemplifi the ndk in the framework of text categor use the dewey document classif ddc as the target scheme our evalu show that the power kernel produc f score that are compar to the refer kernel but is except for the linear kernel faster to comput final we show how to extend the ndk approach by includ the mahalanobi distanc"}
{"id": "1601.00934", "submitter": "J\\\"org Stoye", "authors": "Hiroaki Kaido and Francesca Molinari and J\\\"org Stoye", "title": "Confidence Intervals for Projections of Partially Identified Parameters", "comments": "This version is identical to the paper forthcoming at Econometrica\n  and includes the online appendix", "journal-ref": "Econometrics, Volume 87, Issue 4, July 2019, Pages 1397-1432", "doi": "10.3982/ECTA14075", "report-no": null, "categories": "math.ST econ.EM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a bootstrap-based calibrated projection procedure to build\nconfidence intervals for single components and for smooth functions of a\npartially identified parameter vector in moment (in)equality models. The method\ncontrols asymptotic coverage uniformly over a large class of data generating\nprocesses. The extreme points of the calibrated projection confidence interval\nare obtained by extremizing the value of the function of interest subject to a\nproper relaxation of studentized sample analogs of the moment (in)equality\nconditions. The degree of relaxation, or critical level, is calibrated so that\nthe function of theta, not theta itself, is uniformly asymptotically covered\nwith prespecified probability. This calibration is based on repeatedly checking\nfeasibility of linear programming problems, rendering it computationally\nattractive.\n  Nonetheless, the program defining an extreme point of the confidence interval\nis generally nonlinear and potentially intricate. We provide an algorithm,\nbased on the response surface method for global optimization, that approximates\nthe solution rapidly and accurately, and we establish its rate of convergence.\nThe algorithm is of independent interest for optimization problems with simple\nobjectives and complicated constraints. An empirical application estimating an\nentry game illustrates the usefulness of the method. Monte Carlo simulations\nconfirm the accuracy of the solution algorithm, the good statistical as well as\ncomputational performance of calibrated projection (including in comparison to\nother methods), and the algorithm's potential to greatly accelerate computation\nof other confidence intervals.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 18:45:22 GMT"}, {"version": "v2", "created": "Wed, 1 Nov 2017 18:06:01 GMT"}, {"version": "v3", "created": "Mon, 21 Jan 2019 16:09:17 GMT"}, {"version": "v4", "created": "Wed, 5 Jun 2019 19:22:01 GMT"}], "update_date": "2024-07-03", "authors_parsed": [["Kaido", "Hiroaki", ""], ["Molinari", "Francesca", ""], ["Stoye", "Jörg", ""]], "citation_count": 71, "citation_status": "ok_openalex_doi", "processed_content": "confid interv for project of partial identifi paramet we propos a bootstrap base calibr project procedur to build confid interv for singl compon and for smooth function of a partial identifi paramet vector in moment in equal model the method control asymptot coverag uniformli over a larg class of data gener process the extrem point of the calibr project confid interv are obtain by extrem the valu of the function of interest subject to a proper relax of student sampl analog of the moment in equal condit the degre of relax or critic level is calibr so that the function of theta not theta itself is uniformli asymptot cover with prespecifi probabl thi calibr is base on repeatedli check feasibl of linear program problem render it comput attract nonetheless the program defin an extrem point of the confid interv is gener nonlinear and potenti intric we provid an algorithm base on the respons surfac method for global optim that approxim the solut rapidli and accur and we establish it rate of converg the algorithm is of independ interest for optim problem with simpl object and complic constraint an empir applic estim an entri game illustr the use of the method mont carlo simul confirm the accuraci of the solut algorithm the good statist as well as comput perform of calibr project includ in comparison to other method and the algorithm s potenti to greatli acceler comput of other confid interv"}
{"id": "1601.00955", "submitter": "Feng Nan", "authors": "Feng Nan, Joseph Wang, Venkatesh Saligrama", "title": "Optimally Pruning Decision Tree Ensembles With Feature Cost", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning decision rules for prediction with\nfeature budget constraint. In particular, we are interested in pruning an\nensemble of decision trees to reduce expected feature cost while maintaining\nhigh prediction accuracy for any test example. We propose a novel 0-1 integer\nprogram formulation for ensemble pruning. Our pruning formulation is general -\nit takes any ensemble of decision trees as input. By explicitly accounting for\nfeature-sharing across trees together with accuracy/cost trade-off, our method\nis able to significantly reduce feature cost by pruning subtrees that introduce\nmore loss in terms of feature cost than benefit in terms of prediction accuracy\ngain. Theoretically, we prove that a linear programming relaxation produces the\nexact solution of the original integer program. This allows us to use efficient\nconvex optimization tools to obtain an optimally pruned ensemble for any given\nbudget. Empirically, we see that our pruning algorithm significantly improves\nthe performance of the state of the art ensemble method BudgetRF.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 20:38:35 GMT"}], "update_date": "2016-01-06", "authors_parsed": [["Nan", "Feng", ""], ["Wang", "Joseph", ""], ["Saligrama", "Venkatesh", ""]], "citation_count": 1, "citation_status": "ok_openalex_title", "processed_content": "optim prune decis tree ensembl with featur cost we consid the problem of learn decis rule for predict with featur budget constraint in particular we are interest in prune an ensembl of decis tree to reduc expect featur cost while maintain high predict accuraci for ani test exampl we propos a novel 0 1 integ program formul for ensembl prune our prune formul is gener it take ani ensembl of decis tree as input by explicitli account for featur share across tree togeth with accuraci cost trade off our method is abl to significantli reduc featur cost by prune subtre that introduc more loss in term of featur cost than benefit in term of predict accuraci gain theoret we prove that a linear program relax produc the exact solut of the origin integ program thi allow us to use effici convex optim tool to obtain an optim prune ensembl for ani given budget empir we see that our prune algorithm significantli improv the perform of the state of the art ensembl method budgetrf"}
{"id": "1601.00960", "submitter": "Andong Zhan", "authors": "Andong Zhan, Max A. Little, Denzil A. Harris, Solomon O. Abiola, E.\n  Ray Dorsey, Suchi Saria, and Andreas Terzis", "title": "High Frequency Remote Monitoring of Parkinson's Disease via Smartphone:\n  Platform Overview and Medication Response Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: The aim of this study is to develop a smartphone-based\nhigh-frequency remote monitoring platform, assess its feasibility for remote\nmonitoring of symptoms in Parkinson's disease, and demonstrate the value of\ndata collected using the platform by detecting dopaminergic medication\nresponse. Methods: We have developed HopkinsPD, a novel smartphone-based\nmonitoring platform, which measures symptoms actively (i.e. data are collected\nwhen a suite of tests is initiated by the individual at specific times during\nthe day), and passively (i.e. data are collected continuously in the\nbackground). After data collection, we extract features to assess measures of\nfive key behaviors related to PD symptoms -- voice, balance, gait, dexterity,\nand reaction time. A random forest classifier is used to discriminate\nmeasurements taken after a dose of medication (treatment) versus before the\nmedication dose (baseline). Results: A worldwide study for remote PD monitoring\nwas established using HopkinsPD in July, 2014. This study used entirely remote,\nonline recruitment and installation, demonstrating highly cost-effective\nscalability. In six months, 226 individuals (121 PD and 105 controls)\ncontributed over 46,000 hours of passive monitoring data and approximately\n8,000 instances of structured tests of voice, balance, gait, reaction, and\ndexterity. To the best of our knowledge, this is the first study to have\ncollected data at such a scale for remote PD monitoring. Moreover, we\ndemonstrate the initial ability to discriminate treatment from baseline with\n71.0(+-0.4)% accuracy, which suggests medication response can be monitored\nremotely via smartphone-based measures.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 20:49:09 GMT"}], "update_date": "2016-01-06", "authors_parsed": [["Zhan", "Andong", ""], ["Little", "Max A.", ""], ["Harris", "Denzil A.", ""], ["Abiola", "Solomon O.", ""], ["Dorsey", "E. Ray", ""], ["Saria", "Suchi", ""], ["Terzis", "Andreas", ""]], "citation_count": 54, "citation_status": "ok_openalex_title", "processed_content": "high frequenc remot monitor of parkinson s diseas via smartphon platform overview and medic respons detect object the aim of thi studi is to develop a smartphon base high frequenc remot monitor platform assess it feasibl for remot monitor of symptom in parkinson s diseas and demonstr the valu of data collect use the platform by detect dopaminerg medic respons method we have develop hopkinspd a novel smartphon base monitor platform which measur symptom activ i e data are collect when a suit of test is initi by the individu at specif time dure the day and passiv i e data are collect continu in the background after data collect we extract featur to assess measur of five key behavior relat to pd symptom voic balanc gait dexter and reaction time a random forest classifi is use to discrimin measur taken after a dose of medic treatment versu befor the medic dose baselin result a worldwid studi for remot pd monitor wa establish use hopkinspd in juli 2014 thi studi use entir remot onlin recruit and instal demonstr highli cost effect scalabl in six month 226 individu 121 pd and 105 control contribut over 46 000 hour of passiv monitor data and approxim 8 000 instanc of structur test of voic balanc gait reaction and dexter to the best of our knowledg thi is the first studi to have collect data at such a scale for remot pd monitor moreov we demonstr the initi abil to discrimin treatment from baselin with 71 0 0 4 accuraci which suggest medic respons can be monitor remot via smartphon base measur"}
{"id": "1601.00978", "submitter": "Joseph Paul Cohen", "authors": "Joseph Paul Cohen and Henry Z. Lo and Tingting Lu and Wei Ding", "title": "Crater Detection via Convolutional Neural Networks", "comments": "2 Pages. Submitted to 47th Lunar and Planetary Science Conference\n  (LPSC 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Craters are among the most studied geomorphic features in the Solar System\nbecause they yield important information about the past and present geological\nprocesses and provide information about the relative ages of observed geologic\nformations. We present a method for automatic crater detection using advanced\nmachine learning to deal with the large amount of satellite imagery collected.\nThe challenge of automatically detecting craters comes from their is complex\nsurface because their shape erodes over time to blend into the surface.\nBandeira provided a seminal dataset that embodied this challenge that is still\nan unsolved pattern recognition problem to this day. There has been work to\nsolve this challenge based on extracting shape and contrast features and then\napplying classification models on those features. The limiting factor in this\nexisting work is the use of hand crafted filters on the image such as Gabor or\nSobel filters or Haar features. These hand crafted methods rely on domain\nknowledge to construct. We would like to learn the optimal filters and features\nbased on training examples. In order to dynamically learn filters and features\nwe look to Convolutional Neural Networks (CNNs) which have shown their\ndominance in computer vision. The power of CNNs is that they can learn image\nfilters which generate features for high accuracy classification.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 21:03:59 GMT"}], "update_date": "2016-01-07", "authors_parsed": [["Cohen", "Joseph Paul", ""], ["Lo", "Henry Z.", ""], ["Lu", "Tingting", ""], ["Ding", "Wei", ""]], "citation_count": 34, "citation_status": "ok_openalex_title", "processed_content": "crater detect via convolut neural network crater are among the most studi geomorph featur in the solar system becaus they yield import inform about the past and present geolog process and provid inform about the rel age of observ geolog format we present a method for automat crater detect use advanc machin learn to deal with the larg amount of satellit imageri collect the challeng of automat detect crater come from their is complex surfac becaus their shape erod over time to blend into the surfac bandeira provid a semin dataset that embodi thi challeng that is still an unsolv pattern recognit problem to thi day there ha been work to solv thi challeng base on extract shape and contrast featur and then appli classif model on those featur the limit factor in thi exist work is the use of hand craft filter on the imag such as gabor or sobel filter or haar featur these hand craft method reli on domain knowledg to construct we would like to learn the optim filter and featur base on train exampl in order to dynam learn filter and featur we look to convolut neural network cnn which have shown their domin in comput vision the power of cnn is that they can learn imag filter which gener featur for high accuraci classif"}
{"id": "1601.00987", "submitter": "Sarah Muldoon", "authors": "Sarah Feldt Muldoon, Fabio Pasqualetti, Shi Gu, Matthew Cieslak, Scott\n  T. Grafton, Jean M. Vettel, and Danielle S. Bassett", "title": "Stimulation-based control of dynamic brain networks", "comments": "54 pages, 10 figures, includes Supplementary Information", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to modulate brain states using targeted stimulation is\nincreasingly being employed to treat neurological disorders and to enhance\nhuman performance. Despite the growing interest in brain stimulation as a form\nof neuromodulation, much remains unknown about the network-level impact of\nthese focal perturbations. To study the system wide impact of regional\nstimulation, we employ a data-driven computational model of nonlinear brain\ndynamics to systematically explore the effects of targeted stimulation.\nValidating predictions from network control theory, we uncover the relationship\nbetween regional controllability and the focal versus global impact of\nstimulation, and we relate these findings to differences in the underlying\nnetwork architecture. Finally, by mapping brain regions to cognitive systems,\nwe observe that the default mode system imparts large global change despite\nbeing highly constrained by structural connectivity. This work forms an\nimportant step towards the development of personalized stimulation protocols\nfor medical treatment or performance enhancement.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 21:33:24 GMT"}], "update_date": "2016-01-07", "authors_parsed": [["Muldoon", "Sarah Feldt", ""], ["Pasqualetti", "Fabio", ""], ["Gu", "Shi", ""], ["Cieslak", "Matthew", ""], ["Grafton", "Scott T.", ""], ["Vettel", "Jean M.", ""], ["Bassett", "Danielle S.", ""]], "citation_count": 306, "citation_status": "ok_openalex_title", "processed_content": "stimul base control of dynam brain network the abil to modul brain state use target stimul is increasingli be employ to treat neurolog disord and to enhanc human perform despit the grow interest in brain stimul as a form of neuromodul much remain unknown about the network level impact of these focal perturb to studi the system wide impact of region stimul we employ a data driven comput model of nonlinear brain dynam to systemat explor the effect of target stimul valid predict from network control theori we uncov the relationship between region control and the focal versu global impact of stimul and we relat these find to differ in the underli network architectur final by map brain region to cognit system we observ that the default mode system impart larg global chang despit be highli constrain by structur connect thi work form an import step toward the develop of person stimul protocol for medic treatment or perform enhanc"}
{"id": "1601.00992", "submitter": "Bruce Desmarais", "authors": "Jake Bowers, Bruce A. Desmarais, Mark Frederickson, Nahomi Ichino,\n  Hsuan-Wei Lee, Simi Wang", "title": "Models, Methods and Network Topology: Experimental Design for the Study\n  of Interference", "comments": null, "journal-ref": "Jake Bowers, Bruce A. Desmarais, Mark Frederickson, Nahomi Ichino,\n  Hsuan-Wei Lee, Simi Wang, Models, methods and network topology: Experimental\n  design for the study of interference, Social Networks, Volume 54, 2018, Pages\n  196-208", "doi": "10.1016/j.socnet.2018.01.010", "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How should a network experiment be designed to achieve high statistical\npower? Ex- perimental treatments on networks may spread. Randomizing assignment\nof treatment to nodes enhances learning about the counterfactual causal effects\nof a social network experiment and also requires new methodology (ex. Aronow\nand Samii 2017a; Bow- ers et al. 2013; Toulis and Kao 2013). In this paper we\nshow that the way in which a treatment propagates across a social network\naffects the statistical power of an ex- perimental design. As such, prior\ninformation regarding treatment propagation should be incorporated into the\nexperimental design. Our findings justify reconsideration of standard practice\nin circumstances where units are presumed to be independent even in simple\nexperiments: information about treatment effects is not maximized when we\nassign half the units to treatment and half to control. We also present an\nexam- ple in which statistical power depends on the extent to which the network\ndegree of nodes is correlated with treatment assignment probability. We\nrecommend that re- searchers think carefully about the underlying treatment\npropagation model motivat- ing their study in designing an experiment on a\nnetwork.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 21:41:35 GMT"}, {"version": "v2", "created": "Tue, 7 Nov 2017 01:34:37 GMT"}, {"version": "v3", "created": "Fri, 30 Mar 2018 09:47:35 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Bowers", "Jake", ""], ["Desmarais", "Bruce A.", ""], ["Frederickson", "Mark", ""], ["Ichino", "Nahomi", ""], ["Lee", "Hsuan-Wei", ""], ["Wang", "Simi", ""]], "citation_count": 5, "citation_status": "ok_openalex_doi", "processed_content": "model method and network topolog experiment design for the studi of interfer how should a network experi be design to achiev high statist power ex periment treatment on network may spread random assign of treatment to node enhanc learn about the counterfactu causal effect of a social network experi and also requir new methodolog ex aronow and samii 2017a bow er et al 2013 touli and kao 2013 in thi paper we show that the way in which a treatment propag across a social network affect the statist power of an ex periment design as such prior inform regard treatment propag should be incorpor into the experiment design our find justifi reconsider of standard practic in circumst where unit are presum to be independ even in simpl experi inform about treatment effect is not maxim when we assign half the unit to treatment and half to control we also present an exam ple in which statist power depend on the extent to which the network degre of node is correl with treatment assign probabl we recommend that re searcher think care about the underli treatment propag model motivat ing their studi in design an experi on a network"}
{"id": "1601.00998", "submitter": "Alexandre Robicquet Alexandre Robicquet", "authors": "Alexandre Robicquet, Alexandre Alahi, Amir Sadeghian, Bryan Anenberg,\n  John Doherty, Eli Wu, and Silvio Savarese", "title": "Forecasting Social Navigation in Crowded Complex Scenes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.RO cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When humans navigate a crowed space such as a university campus or the\nsidewalks of a busy street, they follow common sense rules based on social\netiquette. In this paper, we argue that in order to enable the design of new\nalgorithms that can take fully advantage of these rules to better solve tasks\nsuch as target tracking or trajectory forecasting, we need to have access to\nbetter data in the first place. To that end, we contribute the very first large\nscale dataset (to the best of our knowledge) that collects images and videos of\nvarious types of targets (not just pedestrians, but also bikers, skateboarders,\ncars, buses, golf carts) that navigate in a real-world outdoor environment such\nas a university campus. We present an extensive evaluation where different\nmethods for trajectory forecasting are evaluated and compared. Moreover, we\npresent a new algorithm for trajectory prediction that exploits the complexity\nof our new dataset and allows to: i) incorporate inter-class interactions into\ntrajectory prediction models (e.g, pedestrian vs bike) as opposed to just\nintra-class interactions (e.g., pedestrian vs pedestrian); ii) model the degree\nto which the social forces are regulating an interaction. We call the latter\n\"social sensitivity\"and it captures the sensitivity to which a target is\nresponding to a certain interaction. An extensive experimental evaluation\ndemonstrates the effectiveness of our novel approach.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 22:10:15 GMT"}], "update_date": "2016-01-07", "authors_parsed": [["Robicquet", "Alexandre", ""], ["Alahi", "Alexandre", ""], ["Sadeghian", "Amir", ""], ["Anenberg", "Bryan", ""], ["Doherty", "John", ""], ["Wu", "Eli", ""], ["Savarese", "Silvio", ""]], "citation_count": 26, "citation_status": "ok_openalex_title", "processed_content": "forecast social navig in crowd complex scene when human navig a crow space such as a univers campu or the sidewalk of a busi street they follow common sens rule base on social etiquett in thi paper we argu that in order to enabl the design of new algorithm that can take fulli advantag of these rule to better solv task such as target track or trajectori forecast we need to have access to better data in the first place to that end we contribut the veri first larg scale dataset to the best of our knowledg that collect imag and video of variou type of target not just pedestrian but also biker skateboard car buse golf cart that navig in a real world outdoor environ such as a univers campu we present an extens evalu where differ method for trajectori forecast are evalu and compar moreov we present a new algorithm for trajectori predict that exploit the complex of our new dataset and allow to i incorpor inter class interact into trajectori predict model e g pedestrian vs bike as oppos to just intra class interact e g pedestrian vs pedestrian ii model the degre to which the social forc are regul an interact we call the latter social sensit and it captur the sensit to which a target is respond to a certain interact an extens experiment evalu demonstr the effect of our novel approach"}
{"id": "1601.01001", "submitter": "Christoph Matheja", "authors": "Benjamin Lucien Kaminski, Joost-Pieter Katoen, Christoph Matheja,\n  Federico Olmedo", "title": "Weakest Precondition Reasoning for Expected Run-Times of Probabilistic\n  Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a wp-style calculus for obtaining bounds on the expected\nrun-time of probabilistic programs. Its application includes determining the\n(possibly infinite) expected termination time of a probabilistic program and\nproving positive almost-sure termination - does a program terminate with\nprobability one in finite expected time? We provide several proof rules for\nbounding the run-time of loops, and prove the soundness of the approach with\nrespect to a simple operational model. We show that our approach is a\nconservative extension of Nielson's approach for reasoning about the run-time\nof deterministic programs. We analyze the expected run-time of some example\nprograms including a one-dimensional random walk and the coupon collector\nproblem.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 22:31:57 GMT"}, {"version": "v2", "created": "Tue, 28 Nov 2017 16:22:15 GMT"}], "update_date": "2022-02-17", "authors_parsed": [["Kaminski", "Benjamin Lucien", ""], ["Katoen", "Joost-Pieter", ""], ["Matheja", "Christoph", ""], ["Olmedo", "Federico", ""]], "citation_count": 17, "citation_status": "ok_openalex_title", "processed_content": "weakest precondit reason for expect run time of probabilist program thi paper present a wp style calculu for obtain bound on the expect run time of probabilist program it applic includ determin the possibl infinit expect termin time of a probabilist program and prove posit almost sure termin doe a program termin with probabl one in finit expect time we provid sever proof rule for bound the run time of loop and prove the sound of the approach with respect to a simpl oper model we show that our approach is a conserv extens of nielson s approach for reason about the run time of determinist program we analyz the expect run time of some exampl program includ a one dimension random walk and the coupon collector problem"}
{"id": "1601.01006", "submitter": "Fei Han", "authors": "Fei Han, Brian Reily, William Hoff, Hao Zhang", "title": "Space-Time Representation of People Based on 3D Skeletal Data: A Review", "comments": "Our paper has been accepted by the journal Computer Vision and Image\n  Understanding, see\n  http://www.sciencedirect.com/science/article/pii/S1077314217300279, Computer\n  Vision and Image Understanding, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatiotemporal human representation based on 3D visual perception data is a\nrapidly growing research area. Based on the information sources, these\nrepresentations can be broadly categorized into two groups based on RGB-D\ninformation or 3D skeleton data. Recently, skeleton-based human representations\nhave been intensively studied and kept attracting an increasing attention, due\nto their robustness to variations of viewpoint, human body scale and motion\nspeed as well as the realtime, online performance. This paper presents a\ncomprehensive survey of existing space-time representations of people based on\n3D skeletal data, and provides an informative categorization and analysis of\nthese methods from the perspectives, including information modality,\nrepresentation encoding, structure and transition, and feature engineering. We\nalso provide a brief overview of skeleton acquisition devices and construction\nmethods, enlist a number of public benchmark datasets with skeleton data, and\ndiscuss potential future research directions.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 22:38:36 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2016 06:00:39 GMT"}, {"version": "v3", "created": "Sat, 4 Feb 2017 01:08:55 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Han", "Fei", ""], ["Reily", "Brian", ""], ["Hoff", "William", ""], ["Zhang", "Hao", ""]], "citation_count": 317, "citation_status": "ok_openalex_title", "processed_content": "space time represent of peopl base on 3d skelet data a review spatiotempor human represent base on 3d visual percept data is a rapidli grow research area base on the inform sourc these represent can be broadli categor into two group base on rgb d inform or 3d skeleton data recent skeleton base human represent have been intens studi and kept attract an increas attent due to their robust to variat of viewpoint human bodi scale and motion speed as well as the realtim onlin perform thi paper present a comprehens survey of exist space time represent of peopl base on 3d skelet data and provid an inform categor and analysi of these method from the perspect includ inform modal represent encod structur and transit and featur engin we also provid a brief overview of skeleton acquisit devic and construct method enlist a number of public benchmark dataset with skeleton data and discuss potenti futur research direct"}
{"id": "1601.01008", "submitter": "Zahra Derakhshandeh", "authors": "Zahra Derakhshandeh, Robert Gmyr, Andrea W. Richa, Christian\n  Scheideler, Thim Strothmann", "title": "Universal Coating for Programmable Matter", "comments": "32 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The idea behind universal coating is to have a thin layer of a specific\nsubstance covering an object of any shape so that one can measure a certain\ncondition (like temperature or cracks) at any spot on the surface of the object\nwithout requiring direct access to that spot. We study the universal coating\nproblem in the context of self-organizing programmable matter consisting of\nsimple computational elements, called particles, that can establish and release\nbonds and can actively move in a self-organized way. Based on that matter, we\npresent a worst-case work-optimal universal coating algorithm that uniformly\ncoats any object of arbitrary shape and size that allows a uniform coating. Our\nparticles are anonymous, do not have any global information, have constant-size\nmemory, and utilize only local interactions.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 22:43:20 GMT"}], "update_date": "2016-01-07", "authors_parsed": [["Derakhshandeh", "Zahra", ""], ["Gmyr", "Robert", ""], ["Richa", "Andrea W.", ""], ["Scheideler", "Christian", ""], ["Strothmann", "Thim", ""]], "citation_count": 50, "citation_status": "ok_openalex_title", "processed_content": "univers coat for programm matter the idea behind univers coat is to have a thin layer of a specif substanc cover an object of ani shape so that one can measur a certain condit like temperatur or crack at ani spot on the surfac of the object without requir direct access to that spot we studi the univers coat problem in the context of self organ programm matter consist of simpl comput element call particl that can establish and releas bond and can activ move in a self organ way base on that matter we present a worst case work optim univers coat algorithm that uniformli coat ani object of arbitrari shape and size that allow a uniform coat our particl are anonym do not have ani global inform have constant size memori and util onli local interact"}
{"id": "1601.01019", "submitter": "Shankar Mohan", "authors": "Shankar Mohan, Victor Shia and Ram Vasudevan", "title": "Convex Computation of the Reachable Set for Hybrid Systems with\n  Parametric Uncertainty", "comments": "25 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To verify the correct operation of systems, engineers need to determine the\nset of configurations of a dynamical model that are able to safely reach a\nspecified configuration under a control law. Unfortunately, constructing models\nfor systems interacting in highly dynamic environments is difficult. This paper\naddresses this challenge by presenting a convex optimization method to\nefficiently compute the set of configurations of a polynomial hybrid dynamical\nsystem that are able to safely reach a user defined target set despite\nparametric uncertainty in the model. This class of models describes, for\nexample, legged robots moving over uncertain terrains. The presented approach\nutilizes the notion of occupation measures to describe the evolution of\ntrajectories of a nonlinear hybrid dynamical system with parametric uncertainty\nas a linear equation over measures whose supports coincide with the\ntrajectories under investigation. This linear equation with user defined\nsupport constraints is approximated with vanishing conservatism using a\nhierarchy of semidefinite programs that are each proven to compute an\ninner/outer approximation to the set of initial conditions that can reach the\nuser defined target set safely in spite of uncertainty. The efficacy of this\nmethod is illustrated on a collection of six representative examples.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 23:51:27 GMT"}], "update_date": "2016-01-07", "authors_parsed": [["Mohan", "Shankar", ""], ["Shia", "Victor", ""], ["Vasudevan", "Ram", ""]], "citation_count": 22, "citation_status": "ok_openalex_title", "processed_content": "convex comput of the reachabl set for hybrid system with parametr uncertainti to verifi the correct oper of system engin need to determin the set of configur of a dynam model that are abl to safe reach a specifi configur under a control law unfortun construct model for system interact in highli dynam environ is difficult thi paper address thi challeng by present a convex optim method to effici comput the set of configur of a polynomi hybrid dynam system that are abl to safe reach a user defin target set despit parametr uncertainti in the model thi class of model describ for exampl leg robot move over uncertain terrain the present approach util the notion of occup measur to describ the evolut of trajectori of a nonlinear hybrid dynam system with parametr uncertainti as a linear equat over measur whose support coincid with the trajectori under investig thi linear equat with user defin support constraint is approxim with vanish conservat use a hierarchi of semidefinit program that are each proven to comput an inner outer approxim to the set of initi condit that can reach the user defin target set safe in spite of uncertainti the efficaci of thi method is illustr on a collect of six repres exampl"}
{"id": "1601.01038", "submitter": "Michael Monagan", "authors": "Mark van Hoeij and Michael Monagan", "title": "A Modular Algorithm for Computing Polynomial GCDs over Number Fields\n  presented with Multiple Extensions", "comments": "36 pages. An early version of this paper appeared in the Proceedings\n  of ISSAC 2002, ACM Press, pp. 207-213. This version represents work done\n  between 2003 and 2005 outlined as contributions 3, 4 and 5 in the abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of computing the monic gcd of two polynomials over a\nnumber field L = Q(alpha_1,...,alpha_n). Langemyr and McCallum have already\nshown how Brown's modular GCD algorithm for polynomials over Q can be modified\nto work for Q(alpha) and subsequently, Langemyr extended the algorithm to L[x].\nEncarnacion also showed how to use rational number to make the algorithm for\nQ(alpha) output sensitive, that is, the number of primes used depends on the\nsize of the integers in the gcd and not on bounds based on the input\npolynomials.\n  Our first contribution is an extension of Encarnacion's modular GCD algorithm\nto the case n>1, which, like Encarnacion's algorithm, is is output sensitive.\n  Our second contribution is a proof that it is not necessary to test if p\ndivides the discriminant. This simplifies the algorithm; it is correct without\nthis test.\n  Our third contribution is a modification to the algorithm to treat the case\nof reducible extensions. Such cases arise when solving systems of polynomial\nequations.\n  Our fourth contribution is an implementation of the modular GCD algorithm in\nMaple and in Magma. Both implementations use a recursive dense polynomial data\nstructure for representing polynomials over number fields with multiple field\nextensions.\n  Our fifth contribution is a primitive fraction-free algorithm. This is the\nbest non-modular approach. We present timing comparisons of the Maple and Magma\nimplementations demonstrating various optimizations and comparing them with the\nmonic Euclidan algorithm and our primitive fraction-free algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2016 01:03:52 GMT"}], "update_date": "2016-01-07", "authors_parsed": [["van Hoeij", "Mark", ""], ["Monagan", "Michael", ""]], "citation_count": 0, "citation_status": "ok_openalex_title", "processed_content": "a modular algorithm for comput polynomi gcd over number field present with multipl extens we consid the problem of comput the monic gcd of two polynomi over a number field l q alpha_1 alpha_n langemyr and mccallum have alreadi shown how brown s modular gcd algorithm for polynomi over q can be modifi to work for q alpha and subsequ langemyr extend the algorithm to l x encarnacion also show how to use ration number to make the algorithm for q alpha output sensit that is the number of prime use depend on the size of the integ in the gcd and not on bound base on the input polynomi our first contribut is an extens of encarnacion s modular gcd algorithm to the case n 1 which like encarnacion s algorithm is is output sensit our second contribut is a proof that it is not necessari to test if p divid the discrimin thi simplifi the algorithm it is correct without thi test our third contribut is a modif to the algorithm to treat the case of reduc extens such case aris when solv system of polynomi equat our fourth contribut is an implement of the modular gcd algorithm in mapl and in magma both implement use a recurs dens polynomi data structur for repres polynomi over number field with multipl field extens our fifth contribut is a primit fraction free algorithm thi is the best non modular approach we present time comparison of the mapl and magma implement demonstr variou optim and compar them with the monic euclidan algorithm and our primit fraction free algorithm"}
{"id": "1601.01039", "submitter": "Jiguo Cao", "authors": "Baisen Liu and Jiguo Cao", "title": "Estimating Functional Linear Mixed-Effects Regression Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The functional linear model is a popular tool to investigate the relationship\nbetween a scalar/functional response variable and a scalar/functional\ncovariate. We generalize this model to a functional linear mixed-effects model\nwhen repeated measurements are available on multiple subjects. Each subject has\nan individual intercept and slope function, while shares common population\nintercept and slope function. This model is flexible in the sense of allowing\nthe slope random effects to change with the time. We propose a penalized spline\nsmoothing method to estimate the population and random slope functions. A\nREML-based EM algorithm is developed to estimate the variance parameters for\nthe random effects and the data noise. Simulation studies show that our\nestimation method provides an accurate estimate for the functional linear\nmixed-effects model with the finite samples. The functional linear\nmixed-effects model is demonstrated by investigating the effect of the 24-hour\nnitrogen dioxide on the daily maximum ozone concentrations and also studying\nthe effect of the daily temperature on the annual precipitation.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2016 01:04:59 GMT"}], "update_date": "2016-01-07", "authors_parsed": [["Liu", "Baisen", ""], ["Cao", "Jiguo", ""]], "citation_count": 22, "citation_status": "ok_openalex_title", "processed_content": "estim function linear mix effect regress model the function linear model is a popular tool to investig the relationship between a scalar function respons variabl and a scalar function covari we gener thi model to a function linear mix effect model when repeat measur are avail on multipl subject each subject ha an individu intercept and slope function while share common popul intercept and slope function thi model is flexibl in the sens of allow the slope random effect to chang with the time we propos a penal spline smooth method to estim the popul and random slope function a reml base em algorithm is develop to estim the varianc paramet for the random effect and the data nois simul studi show that our estim method provid an accur estim for the function linear mix effect model with the finit sampl the function linear mix effect model is demonstr by investig the effect of the 24 hour nitrogen dioxid on the daili maximum ozon concentr and also studi the effect of the daili temperatur on the annual precipit"}
{"id": "1601.01045", "submitter": "Deepesh Bhati Mr.", "authors": "Deepesh Bhati, Mohd. Aamir Malik and K.K. Jose", "title": "A new 3-parameter extension of generalized lindley distribution", "comments": "15 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here, we introduce a new class of Lindley generated distributions which\nresults in more flexible model with increasing failure rate (IFR), decreasing\nfailure rate(DFR) and up-side down hazard functions for different choices of\nparametric values. We explore, various distributional properties including\nlimiting distribution of extreme order statistics explored. Maximum likelihood\nestimators and the confidence intervals of the parameters are obtained. The\napplicability of the proposed distribution is shown through modelling two sets\nof real data on bladder cancer patients and waiting time in a queue. Further,\nwe carry out stress-strength analysis for applying the model in system\nreliability studies.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2016 01:44:47 GMT"}], "update_date": "2016-01-07", "authors_parsed": [["Bhati", "Deepesh", ""], ["Malik", "Mohd. Aamir", ""], ["Jose", "K. K.", ""]], "citation_count": 4, "citation_status": "ok_openalex_title", "processed_content": "a new 3 paramet extens of gener lindley distribut here we introduc a new class of lindley gener distribut which result in more flexibl model with increas failur rate ifr decreas failur rate dfr and up side down hazard function for differ choic of parametr valu we explor variou distribut properti includ limit distribut of extrem order statist explor maximum likelihood estim and the confid interv of the paramet are obtain the applic of the propos distribut is shown through model two set of real data on bladder cancer patient and wait time in a queue further we carri out stress strength analysi for appli the model in system reliabl studi"}
{"id": "1601.01050", "submitter": "Michael Bukatin", "authors": "Michael Bukatin and Steve Matthews", "title": "Dataflow Graphs as Matrices and Programming with Higher-order Matrix\n  Elements", "comments": "8 pages, August 27, 2015 preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider dataflow architecture for two classes of computations which admit\ntaking linear combinations of execution runs: probabilistic sampling and\ngeneralized animation. We improve the earlier technique of almost continuous\nprogram transformations by adopting a discipline of bipartite graphs linking\nnodes obtained via general transformations and nodes obtained via linear\ntransformations which makes it possible to develop and evolve dataflow programs\nover these classes of computations by continuous program transformations. The\nuse of bipartite graphs allows us to represent the dataflow programs from this\nclass as matrices of real numbers and evolve and modify programs by continuous\nchange of these numbers.\n  We develop a formalism for higher-order dataflow programming for this class\nof dataflow graphs based on the higher-order matrix elements. Some of our\nsoftware experiments are briefly discussed.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2016 02:07:18 GMT"}], "update_date": "2016-01-12", "authors_parsed": [["Bukatin", "Michael", ""], ["Matthews", "Steve", ""]], "citation_count": 1, "citation_status": "ok_openalex_title", "processed_content": "dataflow graph as matric and program with higher order matrix element we consid dataflow architectur for two class of comput which admit take linear combin of execut run probabilist sampl and gener anim we improv the earlier techniqu of almost continu program transform by adopt a disciplin of bipartit graph link node obtain via gener transform and node obtain via linear transform which make it possibl to develop and evolv dataflow program over these class of comput by continu program transform the use of bipartit graph allow us to repres the dataflow program from thi class as matric of real number and evolv and modifi program by continu chang of these number we develop a formal for higher order dataflow program for thi class of dataflow graph base on the higher order matrix element some of our softwar experi are briefli discuss"}
{"id": "1601.01054", "submitter": "Matthew A. Wright", "authors": "Matthew A. Wright, Gabriel Gomes, Roberto Horowitz, Alex A.\n  Kurzhanskiy", "title": "On node models for high-dimensional road networks", "comments": "The abstract on this info page is slightly abbreviated, please see\n  the paper for the full abstract", "journal-ref": "Transportation Research Part B: Methodological, vol. 105, pp.\n  212-234, November 2017", "doi": "10.1016/j.trb.2017.09.001", "report-no": null, "categories": "cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Macroscopic traffic models are necessary for simulation and study of\ntraffic's complex macro-scale dynamics, and are often used by practitioners for\nroad network planning, integrated corridor management, and other applications.\nThese models have two parts: a link model, which describes traffic flow\nbehavior on individual roads, and a node model, which describes behavior at\nroad junctions. As the road networks under study become larger and more complex\n--- nowadays often including arterial networks --- the node model becomes more\nimportant. This paper focuses on the first order node model and has two main\ncontributions. First, we formalize the multi-commodity flow distribution at a\njunction as an optimization problem with all the necessary constraints. Most\ninteresting here is the formalization of input flow priorities. Then, we\ndiscuss a very common \"conservation of turning fractions\" or\n\"first-in-first-out\" (FIFO) constraint, and how it often produces unrealistic\nspillback. This spillback occurs when, at a diverge, a queue develops for a\nmovement that only a few lanes service, but FIFO requires that all lanes\nexperience spillback from this queue. As we show, avoiding this unrealistic\nspillback while retaining FIFO in the node model requires complicated network\ntopologies. Our second contribution is a \"partial FIFO\" mechanism that avoids\nthis unrealistic spillback, and a node model and solution algorithm that\nincorporates this mechanism. The partial FIFO mechanism is parameterized\nthrough intervals that describe how individual movements influence each other,\ncan be intuitively described from physical lane geometry and turning movement\nrules, and allows tuning to describe a link as having anything between full\nFIFO and no FIFO. Excepting the FIFO constraint, the present node model also\nfits within the well-established \"general class of first-order node models\" for\nmulti-commodity flows.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2016 02:33:29 GMT"}, {"version": "v2", "created": "Thu, 24 Nov 2016 18:10:33 GMT"}, {"version": "v3", "created": "Sat, 2 Sep 2017 00:20:12 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Wright", "Matthew A.", ""], ["Gomes", "Gabriel", ""], ["Horowitz", "Roberto", ""], ["Kurzhanskiy", "Alex A.", ""]], "citation_count": 20, "citation_status": "ok_openalex_doi", "processed_content": "on node model for high dimension road network macroscop traffic model are necessari for simul and studi of traffic s complex macro scale dynam and are often use by practition for road network plan integr corridor manag and other applic these model have two part a link model which describ traffic flow behavior on individu road and a node model which describ behavior at road junction as the road network under studi becom larger and more complex nowaday often includ arteri network the node model becom more import thi paper focus on the first order node model and ha two main contribut first we formal the multi commod flow distribut at a junction as an optim problem with all the necessari constraint most interest here is the formal of input flow prioriti then we discuss a veri common conserv of turn fraction or first in first out fifo constraint and how it often produc unrealist spillback thi spillback occur when at a diverg a queue develop for a movement that onli a few lane servic but fifo requir that all lane experi spillback from thi queue as we show avoid thi unrealist spillback while retain fifo in the node model requir complic network topolog our second contribut is a partial fifo mechan that avoid thi unrealist spillback and a node model and solut algorithm that incorpor thi mechan the partial fifo mechan is parameter through interv that describ how individu movement influenc each other can be intuit describ from physic lane geometri and turn movement rule and allow tune to describ a link as have anyth between full fifo and no fifo except the fifo constraint the present node model also fit within the well establish gener class of first order node model for multi commod flow"}
{"id": "1601.01058", "submitter": "Gilad Katz", "authors": "Gilad Katz, Lior Rokach", "title": "Wikiometrics: A Wikipedia Based Ranking System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new concept - Wikiometrics - the derivation of metrics and\nindicators from Wikipedia. Wikipedia provides an accurate representation of the\nreal world due to its size, structure, editing policy and popularity. We\ndemonstrate an innovative mining methodology, where different elements of\nWikipedia - content, structure, editorial actions and reader reviews - are used\nto rank items in a manner which is by no means inferior to rankings produced by\nexperts or other methods. We test our proposed method by applying it to two\nreal-world ranking problems: top world universities and academic journals. Our\nproposed ranking methods were compared to leading and widely accepted\nbenchmarks, and were found to be extremely correlative but with the advantage\nof the data being publically available.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2016 02:44:42 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2016 05:25:27 GMT"}], "update_date": "2016-01-11", "authors_parsed": [["Katz", "Gilad", ""], ["Rokach", "Lior", ""]], "citation_count": 12, "citation_status": "ok_openalex_title", "processed_content": "wikiometr a wikipedia base rank system we present a new concept wikiometr the deriv of metric and indic from wikipedia wikipedia provid an accur represent of the real world due to it size structur edit polici and popular we demonstr an innov mine methodolog where differ element of wikipedia content structur editori action and reader review are use to rank item in a manner which is by no mean inferior to rank produc by expert or other method we test our propos method by appli it to two real world rank problem top world univers and academ journal our propos rank method were compar to lead and wide accept benchmark and were found to be extrem correl but with the advantag of the data be public avail"}
{"id": "1601.01060", "submitter": "Deyu Meng", "authors": "Xiangyong Cao, Qian Zhao, Deyu Meng, Yang Chen, Zongben Xu", "title": "Low-rank Matrix Factorization under General Mixture Noise Distributions", "comments": "13 pages, 15 figures", "journal-ref": null, "doi": "10.1109/TIP.2016.2593343", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many computer vision problems can be posed as learning a low-dimensional\nsubspace from high dimensional data. The low rank matrix factorization (LRMF)\nrepresents a commonly utilized subspace learning strategy. Most of the current\nLRMF techniques are constructed on the optimization problems using L1-norm and\nL2-norm losses, which mainly deal with Laplacian and Gaussian noises,\nrespectively. To make LRMF capable of adapting more complex noise, this paper\nproposes a new LRMF model by assuming noise as Mixture of Exponential Power\n(MoEP) distributions and proposes a penalized MoEP (PMoEP) model by combining\nthe penalized likelihood method with MoEP distributions. Such setting\nfacilitates the learned LRMF model capable of automatically fitting the real\nnoise through MoEP distributions. Each component in this mixture is adapted\nfrom a series of preliminary super- or sub-Gaussian candidates. Moreover, by\nfacilitating the local continuity of noise components, we embed Markov random\nfield into the PMoEP model and further propose the advanced PMoEP-MRF model. An\nExpectation Maximization (EM) algorithm and a variational EM (VEM) algorithm\nare also designed to infer the parameters involved in the proposed PMoEP and\nthe PMoEP-MRF model, respectively. The superseniority of our methods is\ndemonstrated by extensive experiments on synthetic data, face modeling,\nhyperspectral image restoration and background subtraction.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2016 02:52:30 GMT"}], "update_date": "2016-09-21", "authors_parsed": [["Cao", "Xiangyong", ""], ["Zhao", "Qian", ""], ["Meng", "Deyu", ""], ["Chen", "Yang", ""], ["Xu", "Zongben", ""]], "citation_count": 115, "citation_status": "ok_openalex_doi", "processed_content": "low rank matrix factor under gener mixtur nois distribut mani comput vision problem can be pose as learn a low dimension subspac from high dimension data the low rank matrix factor lrmf repres a commonli util subspac learn strategi most of the current lrmf techniqu are construct on the optim problem use l1 norm and l2 norm loss which mainli deal with laplacian and gaussian nois respect to make lrmf capabl of adapt more complex nois thi paper propos a new lrmf model by assum nois as mixtur of exponenti power moep distribut and propos a penal moep pmoep model by combin the penal likelihood method with moep distribut such set facilit the learn lrmf model capabl of automat fit the real nois through moep distribut each compon in thi mixtur is adapt from a seri of preliminari super or sub gaussian candid moreov by facilit the local continu of nois compon we emb markov random field into the pmoep model and further propos the advanc pmoep mrf model an expect maxim em algorithm and a variat em vem algorithm are also design to infer the paramet involv in the propos pmoep and the pmoep mrf model respect the supersenior of our method is demonstr by extens experi on synthet data face model hyperspectr imag restor and background subtract"}
{"id": "1601.01067", "submitter": "Xiao-Shan Gao", "authors": "Rui-Juan Jing, Chun-Ming Yuan, Xiao-Shan Gao", "title": "A Polynomial-time Algorithm to Compute Generalized Hermite Normal Form\n  of Matrices over Z[x]", "comments": "2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a polynomial-time algorithm is given to compute the\ngeneralized Hermite normal form for a matrix F over Z[x], or equivalently, the\nreduced Groebner basis of the Z[x]-module generated by the column vectors of F.\nThe algorithm is also shown to be practically more efficient than existing\nalgorithms. The algorithm is based on three key ingredients. First, an F4 style\nalgorithm to compute the Groebner basis is adopted, where a novel prolongation\nis designed such that the coefficient matrices under consideration have\npolynomial sizes. Second, fast algorithms to compute Hermite normal forms of\nmatrices over Z are used. Third, the complexity of the algorithm are guaranteed\nby a nice estimation for the degree and height bounds of the polynomials in the\ngeneralized Hermite normal form.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2016 03:32:37 GMT"}, {"version": "v2", "created": "Thu, 21 Jul 2016 10:43:53 GMT"}], "update_date": "2016-07-22", "authors_parsed": [["Jing", "Rui-Juan", ""], ["Yuan", "Chun-Ming", ""], ["Gao", "Xiao-Shan", ""]], "citation_count": 7, "citation_status": "ok_openalex_title", "processed_content": "a polynomi time algorithm to comput gener hermit normal form of matric over z x in thi paper a polynomi time algorithm is given to comput the gener hermit normal form for a matrix f over z x or equival the reduc groebner basi of the z x modul gener by the column vector of f the algorithm is also shown to be practic more effici than exist algorithm the algorithm is base on three key ingredi first an f4 style algorithm to comput the groebner basi is adopt where a novel prolong is design such that the coeffici matric under consider have polynomi size second fast algorithm to comput hermit normal form of matric over z are use third the complex of the algorithm are guarante by a nice estim for the degre and height bound of the polynomi in the gener hermit normal form"}
{"id": "1601.01069", "submitter": "Yue Yang Dr", "authors": "Yue Yang, Yanling Yin, Zixia Hu", "title": "MAC Protocols Design for Smart Metering Network", "comments": null, "journal-ref": "Automation, Control and Intelligent Systems, 2015; 3(5): 87-94", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The new generation of power metering system - i.e. Advanced Metering\nInfrastructure (AMI) - is expected to enable remote reading, control, demand\nresponse and other advanced functions, based on the integration of a new\ntwo-way communication network, which will be referred as Smart Metering Network\n(SMN). In this paper, we focus on the design principles of multiple access\ncontrol (MAC) protocols for SMN. First, we list several AMI applications and\nits benefits to the current power grid and user experience. Next, we introduces\nseveral features of SMN relevant to the design choice of the MAC protocols,\nincluding the SMN architecture and candidate communication technologies. After\nthat, we propose some performance evaluation metrics, such as scalability\nissue, traffic types, delay and etc, and give a survey of the associated\nresearch issues for the SMN MAC protocols design. In addition, we also note\nprogress within the new IEEE standardization task group (IEEE 802.11ah TG)\ncurrently working to create SMN standards, especially in the MAC protocols\naspect.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2016 03:38:13 GMT"}], "update_date": "2016-01-07", "authors_parsed": [["Yang", "Yue", ""], ["Yin", "Yanling", ""], ["Hu", "Zixia", ""]], "citation_count": 4, "citation_status": "ok_openalex_title", "processed_content": "mac protocol design for smart meter network the new gener of power meter system i e advanc meter infrastructur ami is expect to enabl remot read control demand respons and other advanc function base on the integr of a new two way commun network which will be refer as smart meter network smn in thi paper we focu on the design principl of multipl access control mac protocol for smn first we list sever ami applic and it benefit to the current power grid and user experi next we introduc sever featur of smn relev to the design choic of the mac protocol includ the smn architectur and candid commun technolog after that we propos some perform evalu metric such as scalabl issu traffic type delay and etc and give a survey of the associ research issu for the smn mac protocol design in addit we also note progress within the new ieee standard task group ieee 802 11ah tg current work to creat smn standard especi in the mac protocol aspect"}
{"id": "1601.01070", "submitter": "Binbin Dai", "authors": "Binbin Dai and Wei Yu", "title": "Energy Efficiency of Downlink Transmission Strategies for Cloud Radio\n  Access Networks", "comments": "14 pages, 8 figures, accepted by JSAC Energy-Efficient Techniques for\n  5G Wireless Communication Systems special issue", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the energy efficiency of the cloud radio access network\n(C-RAN), specifically focusing on two fundamental and different downlink\ntransmission strategies, namely the data-sharing strategy and the compression\nstrategy. In the data-sharing strategy, the backhaul links connecting the\ncentral processor (CP) and the base-stations (BSs) are used to carry user\nmessages -- each user's messages are sent to multiple BSs; the BSs locally form\nthe beamforming vectors then cooperatively transmit the messages to the user.\nIn the compression strategy, the user messages are precoded centrally at the\nCP, which forwards a compressed version of the analog beamformed signals to the\nBSs for cooperative transmission. This paper compares the energy efficiencies\nof the two strategies by formulating an optimization problem of minimizing the\ntotal network power consumption subject to user target rate constraints, where\nthe total network power includes the BS transmission power, BS activation\npower, and load-dependent backhaul power. To tackle the discrete and nonconvex\nnature of the optimization problems, we utilize the techniques of reweighted\n$\\ell_1$ minimization and successive convex approximation to devise provably\nconvergent algorithms. Our main finding is that both the optimized data-sharing\nand compression strategies in C-RAN achieve much higher energy efficiency as\ncompared to the non-optimized coordinated multi-point transmission, but their\ncomparative effectiveness in energy saving depends on the user target rate. At\nlow user target rate, data-sharing consumes less total power than compression,\nhowever, as the user target rate increases, the backhaul power consumption for\ndata-sharing increases significantly leading to better energy efficiency of\ncompression at the high user rate regime.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2016 03:38:36 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2016 12:53:44 GMT"}], "update_date": "2016-01-08", "authors_parsed": [["Dai", "Binbin", ""], ["Yu", "Wei", ""]], "citation_count": 234, "citation_status": "ok_openalex_title", "processed_content": "energi effici of downlink transmiss strategi for cloud radio access network thi paper studi the energi effici of the cloud radio access network c ran specif focus on two fundament and differ downlink transmiss strategi name the data share strategi and the compress strategi in the data share strategi the backhaul link connect the central processor cp and the base station bss are use to carri user messag each user s messag are sent to multipl bss the bss local form the beamform vector then cooper transmit the messag to the user in the compress strategi the user messag are precod central at the cp which forward a compress version of the analog beamform signal to the bss for cooper transmiss thi paper compar the energi effici of the two strategi by formul an optim problem of minim the total network power consumpt subject to user target rate constraint where the total network power includ the bs transmiss power bs activ power and load depend backhaul power to tackl the discret and nonconvex natur of the optim problem we util the techniqu of reweight ell_1 minim and success convex approxim to devis provabl converg algorithm our main find is that both the optim data share and compress strategi in c ran achiev much higher energi effici as compar to the non optim coordin multi point transmiss but their compar effect in energi save depend on the user target rate at low user target rate data share consum less total power than compress howev as the user target rate increas the backhaul power consumpt for data share increas significantli lead to better energi effici of compress at the high user rate regim"}
{"id": "1601.01073", "submitter": "Orhan Firat", "authors": "Orhan Firat, Kyunghyun Cho and Yoshua Bengio", "title": "Multi-Way, Multilingual Neural Machine Translation with a Shared\n  Attention Mechanism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose multi-way, multilingual neural machine translation. The proposed\napproach enables a single neural translation model to translate between\nmultiple languages, with a number of parameters that grows only linearly with\nthe number of languages. This is made possible by having a single attention\nmechanism that is shared across all language pairs. We train the proposed\nmulti-way, multilingual model on ten language pairs from WMT'15 simultaneously\nand observe clear performance improvements over models trained on only one\nlanguage pair. In particular, we observe that the proposed model significantly\nimproves the translation quality of low-resource language pairs.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2016 04:00:50 GMT"}], "update_date": "2016-01-07", "authors_parsed": [["Firat", "Orhan", ""], ["Cho", "Kyunghyun", ""], ["Bengio", "Yoshua", ""]], "citation_count": -1, "citation_status": "openalex_title_http_403", "processed_content": "multi way multilingu neural machin translat with a share attent mechan we propos multi way multilingu neural machin translat the propos approach enabl a singl neural translat model to translat between multipl languag with a number of paramet that grow onli linearli with the number of languag thi is made possibl by have a singl attent mechan that is share across all languag pair we train the propos multi way multilingu model on ten languag pair from wmt 15 simultan and observ clear perform improv over model train on onli one languag pair in particular we observ that the propos model significantli improv the translat qualiti of low resourc languag pair"}